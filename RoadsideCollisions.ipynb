{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RoadCollision.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtofighi/RoadsideCollisions/blob/main/RoadCollision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLDRZM5J-snU"
      },
      "source": [
        "# **Canada Roadside Collision Study**\n",
        "\n",
        "> National Collision Database 1999 to 2017 <br>\n",
        "> Source: https://open.canada.ca/data/en/dataset/1eb9eba7-71d1-4b30-9fb1-30cbdab7e63a\n",
        "\n",
        ">>https://opendatatc.blob.core.windows.net/opendatatc/NCDB_1999_to_2017.csv\n",
        "\n",
        "> Let’s now take a look at our dataset attributes and understand their meaning and significance.\n",
        "\n",
        "| Data element \t| Type \t| Code  | Definition \t|\n",
        "|-----------------------\t|-----------------------\t|----------------------------\t|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|\n",
        "| C_YEAR \t| int64 \t| 19yy-20yy  | Year of the collision \t|\n",
        "| C_MNTH \t| int64 \t| 01-12, UU, XX |Month of the collision  \t|\n",
        "| C_WDAY | int64 | 1-7, U, X | Weekday of the collision  \t|\n",
        "| C_HOUR | int64 | 00-23, UU, XX  |Hour of the collision  \t|\n",
        "| C_SEV | category | 1,2, U, X |  The collision severity <br> 1: Collision producing at least one fatality <br> 2: Collision producing non-fatal injury) |\n",
        "| C_VEHS|int64 | 1-98,99, UU, XX | Number of vehicles involved in collision|\n",
        "| C_CONF| category |01-06 , 21-25 , 31-36 , 41 , QQ, UU, XX |  Collision configuration|\n",
        "| C_RCFG| category |01-12 , QQ, UU, XX |Roadway configuration|\n",
        "| C_WTHR | category| 1-7 , Q , U , X|Weather condition|\n",
        "| C_RSUR | category|1-9 , Q , U , X|Road surface|\n",
        "| C_RALN | category| 1-6 , Q , U , X|Road alignment|\n",
        "| C_TRAF | category| 01-18, UU, XX|Traffic control|\n",
        "| V_ID | int64 | 1-98,99, UU|Vehicle sequence number|\n",
        "| V_TYPE | category |00-23, NN, QQ, UU, XX|Vehicle type|\n",
        "| V_YEAR | int64 | 19yy-20yy , NNNN , UUUU , XXXX|Vehicle model year|\n",
        "| P_ID | int64 | 01 - 99 , NN , UU|Person sequence number|\n",
        "| P_SEX | category | F , M , N , U , X|Person sex|\n",
        "| P_AGE | int64 | 00 , 01 – 98 , 99 , NN , UU , XX|Person age|\n",
        "| P_PSN | category |11-13 , 21-23 , 31-33 , 96-99 , NN, QQ, UU, XX|Person position|\n",
        "| P_ISEV | category| 1-3 , N , U , X|Medical treatment required <br> 1: No Injury <br> 2: Injury  <br> 3: Fatality|\n",
        "| P_SAFE | category |01 , 02 , 09-13 , NN, QQ, UU, XX|Safety device used|\n",
        "| P_USER | category |1-5 , U|Road user class|\n",
        "| C_CASE|int64 |  a number, starting from 752 |seems to be the index of data|\n",
        "\n",
        "\n",
        "We have a total of 22 features and our objective is to predict the dependency of the sevirity of a collison (P_ISEV) to these features we will be building and interpreting a classification model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L9-PW6PNwjH"
      },
      "source": [
        "## **0- Import or Install Libraries and General Settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLKnHDElNucb",
        "outputId": "7b488da4-f138-4a30-fea6-17e41b576aee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # for plot\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline\n",
        "\n",
        "!pip install auto-sklearn\n",
        "import autosklearn\n",
        "import autosklearn.classification\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "from autosklearn.metrics import balanced_accuracy, precision, recall, f1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: auto-sklearn in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.7.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.7.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.13)\n",
            "Requirement already satisfied: smac>=0.14 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (57.4.0)\n",
            "Requirement already satisfied: dask<2021.07 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2021.6.2)\n",
            "Requirement already satisfied: scikit-learn<0.25.0,>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.24.2)\n",
            "Requirement already satisfied: distributed<2021.07,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2021.6.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.1.5)\n",
            "Requirement already satisfied: pynisher>=0.6.3 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.6.4)\n",
            "Requirement already satisfied: pyrfr<0.9,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.8.2)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.14 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.4.20)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.0.1)\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2.5.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.0.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (2.4.7)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (0.29.24)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask<2021.07->auto-sklearn) (2021.10.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask<2021.07->auto-sklearn) (0.11.1)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask<2021.07->auto-sklearn) (2.0.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask<2021.07->auto-sklearn) (1.2.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (2.0.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (5.1.1)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2.8.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask<2021.07->auto-sklearn) (0.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.15.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed<2021.07,>=2.2.0->auto-sklearn) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOZNGV4HM1OI"
      },
      "source": [
        "## **1- Load Data**\n",
        "Select One of the methods based on the work progress:\n",
        "\n",
        "A- Data from Main Source [this URL](https://opendatatc.blob.core.windows.net/opendatatc/NCDB_1999_to_2017.csv) <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRawEnJT-eor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58da6dcc-bd90-4ecf-eb3a-0591aeee0a95"
      },
      "source": [
        "# A- Online Data (1999-2017)\n",
        "!wget https://opendatatc.blob.core.windows.net/opendatatc/NCDB_1999_to_2017.csv\n",
        "df_read = pd.read_csv(\"NCDB_1999_to_2017.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-18 20:14:45--  https://opendatatc.blob.core.windows.net/opendatatc/NCDB_1999_to_2017.csv\n",
            "Resolving opendatatc.blob.core.windows.net (opendatatc.blob.core.windows.net)... 52.239.190.36\n",
            "Connecting to opendatatc.blob.core.windows.net (opendatatc.blob.core.windows.net)|52.239.190.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 535032631 (510M) [application/vnd.ms-excel]\n",
            "Saving to: ‘NCDB_1999_to_2017.csv’\n",
            "\n",
            "NCDB_1999_to_2017.c 100%[===================>] 510.25M  12.9MB/s    in 31s     \n",
            "\n",
            "2021-10-18 20:15:17 (16.3 MB/s) - ‘NCDB_1999_to_2017.csv’ saved [535032631/535032631]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FupcjoAolfxg"
      },
      "source": [
        "### **1-1- Assign Loaded Data to Working with Dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alHV6vX68i-Z",
        "outputId": "0536ae3c-807e-48d1-8cd7-76e4825639cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "source": [
        "df = df_read\n",
        "df.info()\n",
        "df.loc[1:2,:]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6772563 entries, 0 to 6772562\n",
            "Data columns (total 23 columns):\n",
            " #   Column  Dtype \n",
            "---  ------  ----- \n",
            " 0   C_YEAR  int64 \n",
            " 1   C_MNTH  object\n",
            " 2   C_WDAY  object\n",
            " 3   C_HOUR  object\n",
            " 4   C_SEV   int64 \n",
            " 5   C_VEHS  object\n",
            " 6   C_CONF  object\n",
            " 7   C_RCFG  object\n",
            " 8   C_WTHR  object\n",
            " 9   C_RSUR  object\n",
            " 10  C_RALN  object\n",
            " 11  C_TRAF  object\n",
            " 12  V_ID    object\n",
            " 13  V_TYPE  object\n",
            " 14  V_YEAR  object\n",
            " 15  P_ID    object\n",
            " 16  P_SEX   object\n",
            " 17  P_AGE   object\n",
            " 18  P_PSN   object\n",
            " 19  P_ISEV  object\n",
            " 20  P_SAFE  object\n",
            " 21  P_USER  object\n",
            " 22  C_CASE  int64 \n",
            "dtypes: int64(3), object(20)\n",
            "memory usage: 1.2+ GB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C_YEAR</th>\n",
              "      <th>C_MNTH</th>\n",
              "      <th>C_WDAY</th>\n",
              "      <th>C_HOUR</th>\n",
              "      <th>C_SEV</th>\n",
              "      <th>C_VEHS</th>\n",
              "      <th>C_CONF</th>\n",
              "      <th>C_RCFG</th>\n",
              "      <th>C_WTHR</th>\n",
              "      <th>C_RSUR</th>\n",
              "      <th>C_RALN</th>\n",
              "      <th>C_TRAF</th>\n",
              "      <th>V_ID</th>\n",
              "      <th>V_TYPE</th>\n",
              "      <th>V_YEAR</th>\n",
              "      <th>P_ID</th>\n",
              "      <th>P_SEX</th>\n",
              "      <th>P_AGE</th>\n",
              "      <th>P_PSN</th>\n",
              "      <th>P_ISEV</th>\n",
              "      <th>P_SAFE</th>\n",
              "      <th>P_USER</th>\n",
              "      <th>C_CASE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1999</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>02</td>\n",
              "      <td>34</td>\n",
              "      <td>UU</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>03</td>\n",
              "      <td>02</td>\n",
              "      <td>01</td>\n",
              "      <td>1987</td>\n",
              "      <td>01</td>\n",
              "      <td>M</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>UU</td>\n",
              "      <td>1</td>\n",
              "      <td>752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1999</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>02</td>\n",
              "      <td>34</td>\n",
              "      <td>UU</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>03</td>\n",
              "      <td>02</td>\n",
              "      <td>01</td>\n",
              "      <td>1987</td>\n",
              "      <td>02</td>\n",
              "      <td>F</td>\n",
              "      <td>20</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>02</td>\n",
              "      <td>2</td>\n",
              "      <td>752</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   C_YEAR C_MNTH C_WDAY C_HOUR  C_SEV  ... P_PSN P_ISEV P_SAFE P_USER C_CASE\n",
              "1    1999      1      1     20      2  ...    11      1     UU      1    752\n",
              "2    1999      1      1     20      2  ...    13      2     02      2    752\n",
              "\n",
              "[2 rows x 23 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNCtEoqQfIfr"
      },
      "source": [
        "\n",
        "### **1-2- Basic Feature Engineering**\n",
        "> Here we convert the object type data columns to categorical or numericals based on the above table data and eliminate the uknown values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx1ixMbVV5O-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e644d6-fd49-4ca8-85b9-3ff6710c76ae"
      },
      "source": [
        "%%time\n",
        "print('-------------------------------------------------------------------------')\n",
        "print('The number of rows for \"df\" DataFrame is               ', df['C_YEAR'].count())\n",
        "from2013to2017 = df[ df.C_YEAR > 2012 ] # ############################################################# > 2012 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "print('The number of rows for \"df\" DataFrame is > 2012        ', from2013to2017['C_YEAR'].count())\n",
        "print('-------------------------------------------------------------------------')\n",
        "Only_two_vehic_untidy = df[df.C_CONF == '41']\n",
        "print('The number of rows for \"Only_two_vehic_untidy\" DataFrame is         ', Only_two_vehic_untidy['C_YEAR'].count())\n",
        "Only_two_vehic_untidy = from2013to2017[from2013to2017.C_CONF == '41']\n",
        "print('The number of rows for \"Only_two_vehic_untidy\" DataFrame is (> 2012)', Only_two_vehic_untidy['C_YEAR'].count())\n",
        "del Only_two_vehic_untidy\n",
        "print('-------------------------------------------------------------------------')\n",
        "## Cleaning and Controling data step by Step\n",
        "#clean_mnth = df[ ( (df.C_MNTH != 'UU') & (df.C_MNTH != 'XX') ) ]                           # type int64 / month cleaned\n",
        "clean_mnth = from2013to2017[ ( (from2013to2017.C_MNTH != 'UU') & (from2013to2017.C_MNTH != 'XX') ) ]         ####### > 2012 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "print('The number of rows for \"df\" DataFrame is > 2012        ', from2013to2017['C_YEAR'].count())\n",
        "print('The number of rows for \"clean_mnth\" DataFrame is       ', clean_mnth['C_YEAR'].count())\n",
        "clean_wday=clean_mnth[ ( (clean_mnth.C_WDAY != 'U') & (clean_mnth.C_WDAY != 'X') ) ]     # type int64 / weekday cleaned\n",
        "del clean_mnth\n",
        "print('The number of rows for \"clean_wday\" DataFrame is ', clean_wday['C_YEAR'].count())\n",
        "clean_hour=clean_wday[ ( (clean_wday.C_HOUR != 'UU') & (clean_wday.C_HOUR != 'XX') ) ]   # type int64 / hour cleaned\n",
        "del clean_wday\n",
        "print('The number of rows for \"clean_hour\" DataFrame is ', clean_hour['C_YEAR'].count())\n",
        "clean_vehs=clean_hour[ ( (clean_hour.C_VEHS != 'UU') & (clean_hour.C_VEHS != 'XX') ) ]   # type int64 / C_VEHS cleaned\n",
        "del clean_hour\n",
        "print('The number of rows for \"clean_vehs\" DataFrame is ', clean_vehs['C_YEAR'].count())\n",
        "# ------------------------------------------------------------------------------------\n",
        "# Only Hit a parked motor vehicle\n",
        "# C_CONF type category\n",
        "two_vehic_untidy = clean_vehs[clean_vehs.C_CONF == '41'] \n",
        "del clean_vehs\n",
        "print('The number of rows for \"two_vehic_untidy\" DataFrame is  ', two_vehic_untidy['C_YEAR'].count())\n",
        "# V_ID type int64\n",
        "two_vehic_untidy_vid_cl = two_vehic_untidy[ ( (two_vehic_untidy.V_ID != 'UU') ) ]\n",
        "del two_vehic_untidy\n",
        "print('The number of rows for \"two_vehic_untidy_vid_cl\" DataFrame is  ', two_vehic_untidy_vid_cl['C_YEAR'].count()) \n",
        "# V_YEAR type int64\n",
        "two_vehic_untidy_vye_cl = two_vehic_untidy_vid_cl[ ( ( (two_vehic_untidy_vid_cl.V_YEAR != 'UUUU') & (two_vehic_untidy_vid_cl.V_YEAR != 'XXXX') ) ) & (two_vehic_untidy_vid_cl.V_YEAR != 'NNNN')  ]\n",
        "del two_vehic_untidy_vid_cl\n",
        "print('The number of rows for \"two_vehic_untidy_vye_cl\" DataFrame is  ', two_vehic_untidy_vye_cl['C_YEAR'].count())\n",
        "# P_ID type int64\n",
        "two_vehic_untidy_pid_cl = two_vehic_untidy_vye_cl[ ( (two_vehic_untidy_vye_cl.P_ID != 'NN') & (two_vehic_untidy_vye_cl.P_ID != 'UU' ) ) ]\n",
        "del two_vehic_untidy_vye_cl\n",
        "print('The number of rows for \"two_vehic_untidy_pid_cl\" DataFrame is  ', two_vehic_untidy_pid_cl['C_YEAR'].count())\n",
        "# P_SEX type category\n",
        "two_vehic_untidy_sex_cl = two_vehic_untidy_pid_cl[ (  ( (two_vehic_untidy_pid_cl.P_SEX != 'U') & (two_vehic_untidy_pid_cl.P_SEX != 'X') ) ) & (two_vehic_untidy_pid_cl.P_SEX != 'N')  ]\n",
        "del two_vehic_untidy_pid_cl\n",
        "print('The number of rows for \"two_vehic_untidy_sex_cl\" DataFrame is  ', two_vehic_untidy_sex_cl['C_YEAR'].count())\n",
        "# C_SEV type category\n",
        "two_vehic_untidy_sev_cl = two_vehic_untidy_sex_cl[ ( (two_vehic_untidy_sex_cl.C_SEV != 'U') & (two_vehic_untidy_sex_cl.C_SEV != 'X') )  ] \n",
        "del two_vehic_untidy_sex_cl\n",
        "print('The number of rows for \"two_vehic_untidy_sev_cl\" DataFrame is  ', two_vehic_untidy_sev_cl['C_YEAR'].count())\n",
        "# C_RCFG type category\n",
        "two_vehic_untidy_rcf_cl = two_vehic_untidy_sev_cl[ ( ( (two_vehic_untidy_sev_cl.C_RCFG != 'QQ') & (two_vehic_untidy_sev_cl.C_RCFG != 'UU') ) ) & (two_vehic_untidy_sev_cl.C_RCFG != 'XX')  ]\n",
        "del two_vehic_untidy_sev_cl\n",
        "print('The number of rows for \"two_vehic_untidy_rcf_cl\" DataFrame is  ', two_vehic_untidy_rcf_cl['C_YEAR'].count())\n",
        "# C_WTHR type category\n",
        "two_vehic_untidy_wth_cl = two_vehic_untidy_rcf_cl[ ( ( (two_vehic_untidy_rcf_cl.C_WTHR != 'Q') & (two_vehic_untidy_rcf_cl.C_WTHR != 'U') ) ) & (two_vehic_untidy_rcf_cl.C_WTHR != 'X')  ]\n",
        "del two_vehic_untidy_rcf_cl\n",
        "print('The number of rows for \"two_vehic_untidy_wth_cl\" DataFrame is  ', two_vehic_untidy_wth_cl['C_YEAR'].count())\n",
        "# C_RSUR type category\n",
        "two_vehic_untidy_rsu_cl = two_vehic_untidy_wth_cl[ ( ( (two_vehic_untidy_wth_cl.C_RSUR != 'Q') & (two_vehic_untidy_wth_cl.C_RSUR != 'U') ) ) & (two_vehic_untidy_wth_cl.C_RSUR != 'X')  ]\n",
        "del two_vehic_untidy_wth_cl\n",
        "print('The number of rows for \"two_vehic_untidy_rsu_cl\" DataFrame is  ', two_vehic_untidy_rsu_cl['C_YEAR'].count())\n",
        "# C_RALN type category\n",
        "two_vehic_untidy_ran_cl = two_vehic_untidy_rsu_cl[ ( ( (two_vehic_untidy_rsu_cl.C_RALN != 'Q') & (two_vehic_untidy_rsu_cl.C_RALN != 'U') ) ) & (two_vehic_untidy_rsu_cl.C_RALN != 'X')  ]\n",
        "del two_vehic_untidy_rsu_cl\n",
        "print('The number of rows for \"two_vehic_untidy_ran_cl\" DataFrame is  ', two_vehic_untidy_ran_cl['C_YEAR'].count())\n",
        "# C_TRAF type category\n",
        "two_vehic_untidy_tra_cl = two_vehic_untidy_ran_cl[ ( ( (two_vehic_untidy_ran_cl.C_TRAF != 'QQ') & (two_vehic_untidy_ran_cl.C_TRAF != 'UU') ) ) & (two_vehic_untidy_ran_cl.C_TRAF != 'XX')  ]\n",
        "del two_vehic_untidy_ran_cl\n",
        "print('The number of rows for \"two_vehic_untidy_tra_cl\" DataFrame is  ', two_vehic_untidy_tra_cl['C_YEAR'].count())\n",
        "# V_TYPE type category\n",
        "two_vehic_untidy_typ_cl = two_vehic_untidy_tra_cl[ ( ( (two_vehic_untidy_tra_cl.V_TYPE != 'NN') & (two_vehic_untidy_tra_cl.V_TYPE != 'QQ') ) ) & ( (two_vehic_untidy_tra_cl.V_TYPE != 'UU') & (two_vehic_untidy_tra_cl.V_TYPE != 'XX') )  ]\n",
        "del two_vehic_untidy_tra_cl\n",
        "print('The number of rows for \"two_vehic_untidy_typ_cl\" DataFrame is  ', two_vehic_untidy_typ_cl['C_YEAR'].count())\n",
        "# P_AGE type int64\n",
        "two_vehic_untidy_age_cl = two_vehic_untidy_typ_cl[ (  ( (two_vehic_untidy_typ_cl.P_AGE != 'UU') & (two_vehic_untidy_typ_cl.P_AGE != 'XX') ) ) & (two_vehic_untidy_typ_cl.P_AGE != 'NN')  ]\n",
        "del two_vehic_untidy_typ_cl\n",
        "print('The number of rows for \"two_vehic_untidy_age_cl\" DataFrame is  ', two_vehic_untidy_age_cl['C_YEAR'].count())\n",
        "# P_PSN type category\n",
        "two_vehic_untidy_psn_cl = two_vehic_untidy_age_cl[ ( ( (two_vehic_untidy_age_cl.P_PSN != 'NN') & (two_vehic_untidy_age_cl.P_PSN != 'QQ') ) ) & ( (two_vehic_untidy_age_cl.P_PSN != 'UU') & (two_vehic_untidy_age_cl.P_PSN != 'XX') )  ]\n",
        "del two_vehic_untidy_age_cl\n",
        "print('The number of rows for \"two_vehic_untidy_psn_cl\" DataFrame is  ', two_vehic_untidy_psn_cl['C_YEAR'].count())\n",
        "# P_ISEV type category\n",
        "two_vehic_untidy_ise_cl = two_vehic_untidy_psn_cl[ (  ( (two_vehic_untidy_psn_cl.P_ISEV != 'U') & (two_vehic_untidy_psn_cl.P_ISEV != 'X') ) ) & (two_vehic_untidy_psn_cl.P_ISEV != 'N')  ]\n",
        "del two_vehic_untidy_psn_cl\n",
        "print('The number of rows for \"two_vehic_untidy_ise_cl\" DataFrame is  ', two_vehic_untidy_ise_cl['C_YEAR'].count())\n",
        "# P_SAFE type category\n",
        "two_vehic_untidy_sav_cl = two_vehic_untidy_ise_cl[ (  ( (two_vehic_untidy_ise_cl.P_SAFE != 'UU') & (two_vehic_untidy_ise_cl.P_SAFE != 'XX') ) ) & ( (two_vehic_untidy_ise_cl.P_SAFE != 'QQ') & (two_vehic_untidy_ise_cl.P_SAFE != 'NN') ) ]\n",
        "del two_vehic_untidy_ise_cl\n",
        "print('The number of rows for \"two_vehic_untidy_sav_cl\" DataFrame is  ', two_vehic_untidy_sav_cl['C_YEAR'].count())\n",
        "# P_USER type category\n",
        "two_vehic_untidy_use_cl = two_vehic_untidy_sav_cl[ (two_vehic_untidy_sav_cl.P_USER != 'U') ]\n",
        "del two_vehic_untidy_sav_cl\n",
        "print('The number of rows for \"two_vehic_untidy_use_cl\" DataFrame is  ', two_vehic_untidy_use_cl['C_YEAR'].count())\n",
        "# Cleaned data\n",
        "two_vehic_df = two_vehic_untidy_use_cl\n",
        "del two_vehic_untidy_use_cl\n",
        "print('-------------------------------------------------------------------------')\n",
        "print('The number of rows for \"two_vehic_df\" DataFrame is  ', two_vehic_df['C_YEAR'].count())\n",
        "print('-------------------------------------------------------------------------')\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "print('-------------------------------------------------------------------------')\n",
        "# Replace the \"Sex\" category by \"Number\" category to solve the error in next code\n",
        "two_vehic_df = two_vehic_df.replace('M','0')\n",
        "two_vehic_df = two_vehic_df.replace('F','1')\n",
        "\n",
        "two_vehic_df[['C_YEAR','C_MNTH', 'C_WDAY' , 'C_HOUR', 'C_VEHS' , 'V_ID' , 'V_YEAR' , 'P_ID' , 'P_AGE','C_CASE']] = two_vehic_df[['C_YEAR','C_MNTH', 'C_WDAY' , 'C_HOUR', 'C_VEHS' , 'V_ID' , 'V_YEAR' , 'P_ID' , 'P_AGE','C_CASE']].apply(pd.to_numeric)\n",
        "two_vehic_df[['C_SEV','C_CONF', 'C_RCFG' , 'C_WTHR', 'C_RSUR' , 'C_RALN' , 'C_TRAF' , 'V_TYPE' , 'P_SEX' , 'P_PSN' , 'P_ISEV' ,\t'P_SAFE' ,\t'P_USER' ]] = two_vehic_df[['C_SEV','C_CONF', 'C_RCFG' , 'C_WTHR', 'C_RSUR' , 'C_RALN' , 'C_TRAF' , 'V_TYPE' , 'P_SEX' , 'P_PSN' , 'P_ISEV' ,\t'P_SAFE' ,\t'P_USER' ]].astype('category')\n",
        "two_vehic_df['V_AGE']=two_vehic_df['C_YEAR'] - two_vehic_df['V_YEAR'] + 1\n",
        "number_of_data = two_vehic_df['C_YEAR'].count()\n",
        "two_vehic_df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------\n",
            "The number of rows for \"df\" DataFrame is                6772563\n",
            "The number of rows for \"df\" DataFrame is > 2012         1526265\n",
            "-------------------------------------------------------------------------\n",
            "The number of rows for \"Only_two_vehic_untidy\" DataFrame is          92856\n",
            "The number of rows for \"Only_two_vehic_untidy\" DataFrame is (> 2012) 20156\n",
            "-------------------------------------------------------------------------\n",
            "The number of rows for \"df\" DataFrame is > 2012         1526265\n",
            "The number of rows for \"clean_mnth\" DataFrame is        1526175\n",
            "The number of rows for \"clean_wday\" DataFrame is  1526170\n",
            "The number of rows for \"clean_hour\" DataFrame is  1514948\n",
            "The number of rows for \"clean_vehs\" DataFrame is  1514930\n",
            "The number of rows for \"two_vehic_untidy\" DataFrame is   19955\n",
            "The number of rows for \"two_vehic_untidy_vid_cl\" DataFrame is   19955\n",
            "The number of rows for \"two_vehic_untidy_vye_cl\" DataFrame is   18433\n",
            "The number of rows for \"two_vehic_untidy_pid_cl\" DataFrame is   17299\n",
            "The number of rows for \"two_vehic_untidy_sex_cl\" DataFrame is   11109\n",
            "The number of rows for \"two_vehic_untidy_sev_cl\" DataFrame is   11109\n",
            "The number of rows for \"two_vehic_untidy_rcf_cl\" DataFrame is   9444\n",
            "The number of rows for \"two_vehic_untidy_wth_cl\" DataFrame is   9363\n",
            "The number of rows for \"two_vehic_untidy_rsu_cl\" DataFrame is   9176\n",
            "The number of rows for \"two_vehic_untidy_ran_cl\" DataFrame is   9094\n",
            "The number of rows for \"two_vehic_untidy_tra_cl\" DataFrame is   8799\n",
            "The number of rows for \"two_vehic_untidy_typ_cl\" DataFrame is   8724\n",
            "The number of rows for \"two_vehic_untidy_age_cl\" DataFrame is   8033\n",
            "The number of rows for \"two_vehic_untidy_psn_cl\" DataFrame is   7784\n",
            "The number of rows for \"two_vehic_untidy_ise_cl\" DataFrame is   7310\n",
            "The number of rows for \"two_vehic_untidy_sav_cl\" DataFrame is   6458\n",
            "The number of rows for \"two_vehic_untidy_use_cl\" DataFrame is   6399\n",
            "-------------------------------------------------------------------------\n",
            "The number of rows for \"two_vehic_df\" DataFrame is   6399\n",
            "-------------------------------------------------------------------------\n",
            "-------------------------------------------------------------------------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6399 entries, 5246480 to 6772040\n",
            "Data columns (total 24 columns):\n",
            " #   Column  Non-Null Count  Dtype   \n",
            "---  ------  --------------  -----   \n",
            " 0   C_YEAR  6399 non-null   int64   \n",
            " 1   C_MNTH  6399 non-null   int64   \n",
            " 2   C_WDAY  6399 non-null   int64   \n",
            " 3   C_HOUR  6399 non-null   int64   \n",
            " 4   C_SEV   6399 non-null   category\n",
            " 5   C_VEHS  6399 non-null   int64   \n",
            " 6   C_CONF  6399 non-null   category\n",
            " 7   C_RCFG  6399 non-null   category\n",
            " 8   C_WTHR  6399 non-null   category\n",
            " 9   C_RSUR  6399 non-null   category\n",
            " 10  C_RALN  6399 non-null   category\n",
            " 11  C_TRAF  6399 non-null   category\n",
            " 12  V_ID    6399 non-null   int64   \n",
            " 13  V_TYPE  6399 non-null   category\n",
            " 14  V_YEAR  6399 non-null   int64   \n",
            " 15  P_ID    6399 non-null   int64   \n",
            " 16  P_SEX   6399 non-null   category\n",
            " 17  P_AGE   6399 non-null   int64   \n",
            " 18  P_PSN   6399 non-null   category\n",
            " 19  P_ISEV  6399 non-null   category\n",
            " 20  P_SAFE  6399 non-null   category\n",
            " 21  P_USER  6399 non-null   category\n",
            " 22  C_CASE  6399 non-null   int64   \n",
            " 23  V_AGE   6399 non-null   int64   \n",
            "dtypes: category(13), int64(11)\n",
            "memory usage: 684.8 KB\n",
            "CPU times: user 3.16 s, sys: 53.4 ms, total: 3.21 s\n",
            "Wall time: 3.18 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K5ZEELMp0PV"
      },
      "source": [
        "#### **1-2-2- Dropping Unuseful Columns** _(Only for data loading methods A to D)_ \n",
        " \n",
        "> In _`[  'C_YEAR'  ,  'C_SEV'  ,  'C_CONF'  ,  'V_ID'  ,  'V_YEAR'  ,  'P_ID'  ,  'C_CASE'  ]`_ columns there are no information to help the predict. Therefore, we drop them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY0bbW8NpHD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826bdeb3-327f-4118-82e6-dd485a05d4ee"
      },
      "source": [
        "two_vehic_df = two_vehic_df.drop( ['C_YEAR','C_SEV','C_CONF','V_ID','V_YEAR','P_ID','C_CASE'], axis=1)\n",
        "two_vehic_df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6399 entries, 5246480 to 6772040\n",
            "Data columns (total 17 columns):\n",
            " #   Column  Non-Null Count  Dtype   \n",
            "---  ------  --------------  -----   \n",
            " 0   C_MNTH  6399 non-null   int64   \n",
            " 1   C_WDAY  6399 non-null   int64   \n",
            " 2   C_HOUR  6399 non-null   int64   \n",
            " 3   C_VEHS  6399 non-null   int64   \n",
            " 4   C_RCFG  6399 non-null   category\n",
            " 5   C_WTHR  6399 non-null   category\n",
            " 6   C_RSUR  6399 non-null   category\n",
            " 7   C_RALN  6399 non-null   category\n",
            " 8   C_TRAF  6399 non-null   category\n",
            " 9   V_TYPE  6399 non-null   category\n",
            " 10  P_SEX   6399 non-null   category\n",
            " 11  P_AGE   6399 non-null   int64   \n",
            " 12  P_PSN   6399 non-null   category\n",
            " 13  P_ISEV  6399 non-null   category\n",
            " 14  P_SAFE  6399 non-null   category\n",
            " 15  P_USER  6399 non-null   category\n",
            " 16  V_AGE   6399 non-null   int64   \n",
            "dtypes: category(11), int64(6)\n",
            "memory usage: 422.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otk2KvP_AW3f"
      },
      "source": [
        "## **3- Methods of  `Decision Tree`, `Random Forest`, ` Logistic Regression`, `Naive Bayes`, `k-NN`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2A7asupBbc1"
      },
      "source": [
        "### 3-1- **Data Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPUxxnklqDM1"
      },
      "source": [
        "#### **3-1-1- Create dummy variables based on all variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGQ3fVfmi3ZY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "09763929-e2d8-44d5-cccb-9d3936c17a13"
      },
      "source": [
        "# cat_cols=[['C_MNTH',\t'C_WDAY',\t'C_HOUR',\t'C_VEHS',\t'C_RCFG',\t'C_WTHR',\t'C_RSUR',\t'C_RALN',\t'C_TRAF',\t'V_TYPE',\t'P_SEX',\t'P_AGE',\t'P_PSN',\t'P_ISEV',\t'P_SAFE',\t'P_USER',\t'V_AGE']\n",
        "two_vehic_df[['C_MNTH',\t'C_WDAY',\t'C_HOUR',\t'C_VEHS',\t'C_RCFG',\t'C_WTHR',\t'C_RSUR',\t'C_RALN',\t'C_TRAF',\t'V_TYPE',\t'P_SEX',\t'P_AGE',\t'P_PSN',\t'P_ISEV',\t'P_SAFE',\t'P_USER',\t'V_AGE']] = two_vehic_df[['C_MNTH',\t'C_WDAY',\t'C_HOUR',\t'C_VEHS',\t'C_RCFG',\t'C_WTHR',\t'C_RSUR',\t'C_RALN',\t'C_TRAF',\t'V_TYPE',\t'P_SEX',\t'P_AGE',\t'P_PSN',\t'P_ISEV',\t'P_SAFE',\t'P_USER',\t'V_AGE']].apply(pd.to_numeric)\n",
        "two_vehic_df.info()\n",
        "cat_cols =[]\n",
        "two_vehic_df_cat = pd.get_dummies(two_vehic_df, columns=cat_cols, drop_first=True)\n",
        "two_vehic_df_cat.head(2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6399 entries, 5246480 to 6772040\n",
            "Data columns (total 17 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   C_MNTH  6399 non-null   int64\n",
            " 1   C_WDAY  6399 non-null   int64\n",
            " 2   C_HOUR  6399 non-null   int64\n",
            " 3   C_VEHS  6399 non-null   int64\n",
            " 4   C_RCFG  6399 non-null   int64\n",
            " 5   C_WTHR  6399 non-null   int64\n",
            " 6   C_RSUR  6399 non-null   int64\n",
            " 7   C_RALN  6399 non-null   int64\n",
            " 8   C_TRAF  6399 non-null   int64\n",
            " 9   V_TYPE  6399 non-null   int64\n",
            " 10  P_SEX   6399 non-null   int64\n",
            " 11  P_AGE   6399 non-null   int64\n",
            " 12  P_PSN   6399 non-null   int64\n",
            " 13  P_ISEV  6399 non-null   int64\n",
            " 14  P_SAFE  6399 non-null   int64\n",
            " 15  P_USER  6399 non-null   int64\n",
            " 16  V_AGE   6399 non-null   int64\n",
            "dtypes: int64(17)\n",
            "memory usage: 899.9 KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C_MNTH</th>\n",
              "      <th>C_WDAY</th>\n",
              "      <th>C_HOUR</th>\n",
              "      <th>C_VEHS</th>\n",
              "      <th>C_RCFG</th>\n",
              "      <th>C_WTHR</th>\n",
              "      <th>C_RSUR</th>\n",
              "      <th>C_RALN</th>\n",
              "      <th>C_TRAF</th>\n",
              "      <th>V_TYPE</th>\n",
              "      <th>P_SEX</th>\n",
              "      <th>P_AGE</th>\n",
              "      <th>P_PSN</th>\n",
              "      <th>P_ISEV</th>\n",
              "      <th>P_SAFE</th>\n",
              "      <th>P_USER</th>\n",
              "      <th>V_AGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5246480</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5246511</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         C_MNTH  C_WDAY  C_HOUR  C_VEHS  ...  P_ISEV  P_SAFE  P_USER  V_AGE\n",
              "5246480       1       1      13       2  ...       2       2       1      7\n",
              "5246511       1       1       6       2  ...       2       2       1      4\n",
              "\n",
              "[2 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ5r9DYtNl8d"
      },
      "source": [
        "\n",
        "#### **3-1-2- Balancing the Dataset**\n",
        "https://elitedatascience.com/imbalanced-classes\n",
        "\n",
        "> Downsample majority class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l7RwUUGNje8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6976cc8f-493b-4dd5-e263-df56e7c8a102"
      },
      "source": [
        "two_vehic_df_cat_majority = two_vehic_df_cat[two_vehic_df_cat.P_ISEV==2]\n",
        "two_vehic_df_cat_minority = two_vehic_df_cat[two_vehic_df_cat.P_ISEV==1]\n",
        "print(two_vehic_df_cat_majority.shape[0])\n",
        "print(two_vehic_df_cat_minority.shape[0])\n",
        "from sklearn.utils import resample\n",
        "# Downsample majority class\n",
        "two_vehic_df_cat_majority_downsampled = resample(two_vehic_df_cat_majority, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=two_vehic_df_cat_minority.shape[0],     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        "two_vehic_df_cat_majority_downsampled.shape[0]\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "df_downsampled = pd.concat([two_vehic_df_cat_majority_downsampled, two_vehic_df_cat_minority])\n",
        "df_downsampled.P_ISEV.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4721\n",
            "1654\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1654\n",
              "2    1654\n",
              "Name: P_ISEV, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ48SDouq1E7"
      },
      "source": [
        "#### **3-1-3- Partition into train and test**\n",
        "Use train_test_split from sklearn.model_selection to partition the dataset into 70% for training and 30% for testing.\n",
        "\n",
        "You can use the 70% for training set as both training and validation by using cross-validation.\n",
        "\n",
        "**Train and Test the model**  \n",
        "P_ISEV:<br>\n",
        "\n",
        "|Code| Description|\n",
        "|---------|-----------|\n",
        "|1|No Injury|\n",
        "|2|Injury|\n",
        "|3|Fatality\tDied immediately or within the time limit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd-nC48craqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8baa34d3-6f26-48ef-e1e1-3cc3fb70887c"
      },
      "source": [
        "target = 'P_ISEV' # Collision producing at least one injury\n",
        "features = list(df_downsampled.columns)\n",
        "features = [f for f in features if f!=target]\n",
        "# Separate input features (X) and target variable (y)\n",
        "X = df_downsampled[features]\n",
        "y = df_downsampled[[target]]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
        "\n",
        "print(features)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape) \n",
        "print(X_test.shape) \n",
        "print(y_test.shape)\n",
        "# Make target variable in numpy array format of 0 or 1\n",
        "y_train_b = 1*np.ravel(y_train)\n",
        "y_test_b  = 1*np.ravel(y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['C_MNTH', 'C_WDAY', 'C_HOUR', 'C_VEHS', 'C_RCFG', 'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'V_TYPE', 'P_SEX', 'P_AGE', 'P_PSN', 'P_SAFE', 'P_USER', 'V_AGE']\n",
            "(2315, 16)\n",
            "(2315, 1)\n",
            "(993, 16)\n",
            "(993, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srMv9Rtq-0rb"
      },
      "source": [
        "#### **3-1-4- Scaling Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6wCEWZT_Q8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e96a107-74bd-4623-fde9-b2c22f60d365"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# For all datapoints\n",
        "min_max_scaler_all = MinMaxScaler()\n",
        "#---------------------------------|\n",
        "X_minmax = min_max_scaler_all.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_minmax, columns = X.columns)\n",
        "#---------------------------------\n",
        "print(min_max_scaler_all.scale_)\n",
        "#---------------------------------|\n",
        "print(X_scaled.shape)\n",
        "#---------------------------------\n",
        "# Just based on the training set\n",
        "min_max_scaler = MinMaxScaler()\n",
        "#---------------------------------|\n",
        "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
        "print(min_max_scaler.scale_)\n",
        "X_tr_scaled = pd.DataFrame(X_train_minmax, columns = X_train.columns)\n",
        "\n",
        "print(X_tr_scaled.shape)\n",
        "#---------------------------------\n",
        "# Just based on the test set\n",
        "X_test_minmax = min_max_scaler.transform(X_test)\n",
        "X_te_scaled = pd.DataFrame(X_test_minmax, columns = X_test.columns)\n",
        "print(min_max_scaler.scale_)\n",
        "#---------------------------------\n",
        "print(y_train_b.shape)\n",
        "print(X_tr_scaled.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.09090909 0.16666667 0.04347826 0.07142857 0.125      0.16666667\n",
            " 0.16666667 0.2        0.05882353 0.05       1.         0.01020408\n",
            " 0.01162791 0.08333333 0.25       0.01923077]\n",
            "(3308, 16)\n",
            "[0.09090909 0.16666667 0.04347826 0.07142857 0.125      0.16666667\n",
            " 0.2        0.2        0.05882353 0.05       1.         0.0106383\n",
            " 0.01176471 0.08333333 0.25       0.01923077]\n",
            "(2315, 16)\n",
            "[0.09090909 0.16666667 0.04347826 0.07142857 0.125      0.16666667\n",
            " 0.2        0.2        0.05882353 0.05       1.         0.0106383\n",
            " 0.01176471 0.08333333 0.25       0.01923077]\n",
            "(2315,)\n",
            "(2315, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZDr3zfMD86V"
      },
      "source": [
        "### **3-2- Decision Tree**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOR1QNhW0Gqh"
      },
      "source": [
        "#### **3-2-1- Cross Validation**\n",
        "\n",
        "\n",
        "Use grid search with cross-validation (with the help of the GridSearchCV class) to find good hyperparameter values for a DecisionTreeClassifier.\n",
        "\n",
        "**Use CV=10 in GridSearchDV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCanbY0O0W8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a332e064-a99a-4652-9033-43543dcb6085"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "params = {'criterion': ['gini','entropy'], 'max_leaf_nodes': [3,10,30,100,300,1000,3000], 'min_samples_split': [2, 10, 100], \n",
        "          'max_depth': [3,4, 5,6,7,8,10,12]}\n",
        "dtree_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1, cv=10)\n",
        "#---------------------------------|\n",
        "dtree_cv.fit(X_tr_scaled, y_train_b)\n",
        "#---------------------------------\n",
        "print('dtree_cv.best_params are: ',dtree_cv.best_params_)\n",
        "print('dtree_cv.best_score_ is: ',dtree_cv.best_score_) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 336 candidates, totalling 3360 fits\n",
            "dtree_cv.best_params are:  {'criterion': 'entropy', 'max_depth': 6, 'max_leaf_nodes': 10, 'min_samples_split': 100}\n",
            "dtree_cv.best_score_ is:  0.6405844155844156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NACKQlCkEjRY",
        "outputId": "33f3f545-ba57-45eb-9e9d-71b7647045a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "params = {'criterion': ['gini','entropy'], 'max_leaf_nodes': [3,10,30,100,300,1000,3000], 'min_samples_split': [2, 10, 100], \n",
        "          'max_depth': [3,4]}\n",
        "dtree_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1, cv=10)\n",
        "#---------------------------------|\n",
        "dtree_cv.fit(X_tr_scaled, y_train_b)\n",
        "#---------------------------------\n",
        "print('dtree_cv.best_params are: ',dtree_cv.best_params_)\n",
        "print('dtree_cv.best_score_ is: ',dtree_cv.best_score_)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 84 candidates, totalling 840 fits\n",
            "dtree_cv.best_params are:  {'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 10, 'min_samples_split': 2}\n",
            "dtree_cv.best_score_ is:  0.623300119420809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkvJGjE0QPOC"
      },
      "source": [
        "#### **3-2-2- Measure the performance of your best model on the test set**\n",
        "By measuring the best model performance on the test set, if it is close enough to the validation accuracy after cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH3Oq4deQK0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca85990-e8b7-47ec-a365-5543ec321c3f"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = dtree_cv.predict(X_te_scaled)\n",
        "accuracy_score(y_test_b, y_pred)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6465256797583081"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_GVtez1QsmC"
      },
      "source": [
        "#### **3-2-3- Visualizing the Tree**\n",
        "Let's makes the best tree and visualize it based on the best parameters offered by cross validation {'max_depth': 5, 'max_leaf_nodes': 30, 'min_samples_split': 2}.\n",
        "\n",
        "By visualizing this decision tree, we can see what the most important feature is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecEplkVtQsVi"
      },
      "source": [
        "criterion = dtree_cv.best_params_['criterion']\n",
        "max_depth = dtree_cv.best_params_['max_depth']\n",
        "max_leaf_nodes = dtree_cv.best_params_['max_leaf_nodes']\n",
        "min_samples_split = dtree_cv.best_params_['min_samples_split']\n",
        "\n",
        "dtree=DecisionTreeClassifier(class_weight=None,\n",
        "                                              criterion=criterion,\n",
        "                                              max_depth=max_depth,\n",
        "                                              max_features=None,\n",
        "                                              max_leaf_nodes=max_leaf_nodes,\n",
        "                                              min_impurity_decrease=0.0,\n",
        "                                              min_impurity_split=None,\n",
        "                                              min_samples_leaf=1,\n",
        "                                              min_samples_split=min_samples_split,\n",
        "                                              min_weight_fraction_leaf=0.0,\n",
        "                                              presort=False, random_state=42,\n",
        "                                              splitter='best')\n",
        "\n",
        "dtree.fit(X, y)\n",
        "\n",
        "feature_names = list(X.columns)\n",
        "class_names = list(y.columns)\n",
        "\n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "export_graphviz(dtree, out_file='tree.dot',  feature_names=feature_names,class_names=['1','2'],filled=True, rounded=True,special_characters=True)\n",
        "\n",
        "y_pred = dtree.predict(X)\n",
        "accuracy_score(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJpZYpoOHYXY"
      },
      "source": [
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "dot_data = StringIO()\n",
        "export_graphviz(dtree, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True, feature_names = feature_names,class_names=['1','2'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('collision_decisiontree.png')\n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmZ-PJ-XS9tu"
      },
      "source": [
        "### **3-3- Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOnK4BQ_TNXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46256783-d751-4b52-e1dd-19260f5fbe5a"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "\n",
        "# Choose some parameter combinations to try\n",
        "params = {'n_estimators': [4, 6, 9], \n",
        "              'max_features': ['log2', 'sqrt','auto'], \n",
        "              'criterion': ['entropy', 'gini'],\n",
        "              'max_depth': [2, 3, 5, 10], \n",
        "              'min_samples_split': [2, 3, 5],\n",
        "              'min_samples_leaf': [1,5,8]\n",
        "             }\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "acc_scorer = make_scorer(accuracy_score)\n",
        "\n",
        "# Run the grid search\n",
        "rf_cv = GridSearchCV(RandomForestClassifier(random_state=42), params, scoring=acc_scorer, n_jobs=-1, verbose=1, cv=10)\n",
        "#---------------------------------|\n",
        "rf_grid_seaech = rf_cv.fit(X_tr_scaled,y_train_b)\n",
        "#---------------------------------\n",
        "# the best combination of parameters\n",
        "print(f\"rf_cv.best_params_:{rf_cv.best_params_}\")\n",
        "\n",
        "print( f\"rf_cv.best_score_: {rf_cv.best_score_}\")\n",
        "\n",
        "# Test\n",
        "#---------------------------------|\n",
        "y_pred = rf_cv.predict(X_te_scaled)\n",
        "accuracy_score(y_test_b, y_pred)\n",
        "#---------------------------------\n",
        "# Train the tuned RF on whole data\n",
        "n_estimators = rf_cv.best_params_['n_estimators']\n",
        "max_features = rf_cv.best_params_['max_features']\n",
        "criterion = rf_cv.best_params_['criterion']\n",
        "max_depth = rf_cv.best_params_['max_depth']\n",
        "min_samples_leaf = rf_cv.best_params_['min_samples_leaf']\n",
        "min_samples_split = rf_cv.best_params_['min_samples_split']\n",
        "\n",
        "rf_tuned = RandomForestClassifier(random_state=42,\n",
        "                                  n_estimators= n_estimators,\n",
        "                                  criterion=criterion,\n",
        "                                  max_depth=max_depth,\n",
        "                                  min_samples_leaf=min_samples_leaf,\n",
        "#---------------------------------|\n",
        "                                  min_samples_split=min_samples_split).fit(X_tr_scaled,y_train_b)\n",
        "print(f\"Accuracy of the tuned model: {accuracy_score(y_test_b, rf_tuned.predict(X_te_scaled))}\")\n",
        "#---------------------------------|"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 648 candidates, totalling 6480 fits\n",
            "rf_cv.best_params_:{'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9}\n",
            "rf_cv.best_score_: 0.6375858337065233\n",
            "Accuracy of the tuned model: 0.6535750251762337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUpraCCwTuG0"
      },
      "source": [
        "#### **3-3-1- Feature Importance**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw_l-zFoTtU3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "03aaedc4-6fef-4dec-a022-a4d1a58f4f37"
      },
      "source": [
        "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=42)\n",
        "#---------------------------------|\n",
        "rnd_clf.fit(X_scaled, y)\n",
        "features = X.columns\n",
        "#---------------------------------\n",
        "feature_importance = {}\n",
        "#---------------------------------|\n",
        "for name, importance in zip(X.columns, rnd_clf.feature_importances_):\n",
        "#---------------------------------\n",
        "  feature_importance[name] = importance\n",
        "  \n",
        "feature_importance = [(k, feature_importance[k]) for k in sorted(feature_importance, key=feature_importance.get, reverse=True)]\n",
        "for k, v in feature_importance:\n",
        "  print(f\"{k}: {v:.3}\")\n",
        "\n",
        "importances = rnd_clf.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P_AGE: 0.173\n",
            "C_HOUR: 0.135\n",
            "V_AGE: 0.13\n",
            "C_MNTH: 0.107\n",
            "C_WDAY: 0.0856\n",
            "P_PSN: 0.0489\n",
            "C_VEHS: 0.0462\n",
            "C_WTHR: 0.0381\n",
            "C_RSUR: 0.0357\n",
            "V_TYPE: 0.0337\n",
            "C_RALN: 0.0327\n",
            "C_RCFG: 0.0292\n",
            "P_SAFE: 0.028\n",
            "C_TRAF: 0.027\n",
            "P_SEX: 0.0251\n",
            "P_USER: 0.0244\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERLXa1Lrf4h4"
      },
      "source": [
        "### **3-4- Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQymqMInf4OF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b35e1a-2e86-4c53-9826-d4856816aa02"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "params={'solver':['lbfgs'], 'C':np.logspace(-3,3,7), 'penalty':['l2', 'none']}# l1 lasso l2 ridge\n",
        "logreg=LogisticRegression()\n",
        "logreg_cv=GridSearchCV(logreg,params,n_jobs=-1, verbose=1, cv=10)\n",
        "#---------------------------------|\n",
        "logreg_cv.fit(X_tr_scaled,y_train)\n",
        "#---------------------------------\n",
        "print(f\"Tuned hpyerparameters :(best parameters) {logreg_cv.best_params_}\")\n",
        "print(f\"Accuracy of cross validation is {logreg_cv.best_score_}\")\n",
        "#---------------------------------|\n",
        "print (f\"Accuracy of test is {logreg_cv.score(X_te_scaled, y_test)}\")\n",
        "#---------------------------------\n",
        "C = logreg_cv.best_params_['C']\n",
        "penalty = logreg_cv.best_params_['penalty']\n",
        "#---------------------------------|\n",
        "logreg_tuned = LogisticRegression(random_state=42, solver='lbfgs',C=C, penalty=penalty ).fit(X_scaled, y)\n",
        "print (f\"Accuracy of tuned model is {logreg_cv.score(X_scaled, y)}\")\n",
        "#---------------------------------"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 14 candidates, totalling 140 fits\n",
            "Tuned hpyerparameters :(best parameters) {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Accuracy of cross validation is 0.5908848335572474\n",
            "Accuracy of test is 0.6022155085599195\n",
            "Accuracy of tuned model is 0.6051995163240629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmCRE_kfhabV"
      },
      "source": [
        "### **3-5- Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ChIN44yhc8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f793ce60-fdc8-4b55-b67d-2cc5958c0475"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "params = {}\n",
        "#---------------------------------|\n",
        "nb_cv=GridSearchCV(GaussianNB(),params,n_jobs=-1, verbose=1, cv=5).fit(X_tr_scaled,y_train_b)\n",
        "#---------------------------------\n",
        "print(f\"Accuracy of cross validation is {nb_cv.best_score_}\")\n",
        "#---------------------------------|\n",
        "y_pred = nb_cv.predict(X_te_scaled)\n",
        "accuracy_score(y_test_b, y_pred)\n",
        "#---------------------------------"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Accuracy of cross validation is 0.5520518358531318\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.595166163141994"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jc1McHqiloI"
      },
      "source": [
        "### **3-6- k-NN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYlpouzLi0Qw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09cac290-4812-47c4-c89b-2fbd4085db5a"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "k_range = list(range(1, 31))\n",
        "# we create a list\n",
        "weight_options = ['uniform', 'distance']\n",
        "# create a parameter grid: map the parameter names to the values that should be searched\n",
        "# dictionary = dict(key=values, key=values)\n",
        "param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
        "print(param_grid)\n",
        "#{'weights': ['uniform', 'distance'], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}\n",
        "# instantiate and fit the grid\n",
        "# exhaustive grid-search because it's trying every combination\n",
        "# 10-fold cross-validation is being performed 30 x 2 = 60 times\n",
        "knn_cv = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
        "#---------------------------------|\n",
        "knn_cv.fit(X_tr_scaled, y_train_b)\n",
        "#---------------------------------\n",
        "print(f\"Tuned hpyerparameters :(best parameters) {knn_cv.best_params_}\")\n",
        "print(f\"Accuracy of cross validation is {knn_cv.best_score_}\")\n",
        "#---------------------------------|\n",
        "y_pred = knn_cv.predict(X_te_scaled)\n",
        "print(accuracy_score(y_test_b, y_pred))\n",
        "#---------------------------------"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']}\n",
            "Tuned hpyerparameters :(best parameters) {'n_neighbors': 28, 'weights': 'distance'}\n",
            "Accuracy of cross validation is 0.6012763098969997\n",
            "0.62134944612286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyZwPmyvJdv7"
      },
      "source": [
        "## **3-7- Build and fit a classifier - Auto-Sklearn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLvz1J0gJ1Mn",
        "outputId": "0fdeb5c4-07ab-423a-89a5-f1e9a1d3d51e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def error(solution, prediction):\n",
        "    # custom function defining error\n",
        "    return np.mean(solution != prediction)\n",
        "\n",
        "def get_metric_result(cv_results):\n",
        "    results = pd.DataFrame.from_dict(cv_results)\n",
        "    results = results[results['status'] == \"Success\"]\n",
        "    cols = ['rank_test_scores', 'param_classifier:__choice__', 'mean_test_score']\n",
        "    cols.extend([key for key in cv_results.keys() if key.startswith('metric_')])\n",
        "    return results[cols]\n",
        "\n",
        "error_rate = autosklearn.metrics.make_scorer(\n",
        "    name='custom_error',\n",
        "    score_func=error,\n",
        "    optimum=0,\n",
        "    greater_is_better=False,\n",
        "    needs_proba=False,\n",
        "    needs_threshold=False\n",
        ")\n",
        "cls = autosklearn.classification.AutoSklearnClassifier(\n",
        "    time_left_for_this_task=86400,\n",
        "    per_run_time_limit=300,\n",
        "    scoring_functions=[balanced_accuracy, precision, recall, f1, error_rate]\n",
        ")\n",
        "\n",
        "cls.fit(X_tr_scaled,y_train_b, X_te_scaled, y_test_b)\n",
        "\n",
        "predictions = cls.predict(X_te_scaled)\n",
        "\n",
        "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test_b, predictions))\n",
        "print(\"#\" * 80)\n",
        "print(\"Metric results\")\n",
        "print(get_metric_result(cls.cv_results_).to_string(index=False))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score 0.6565961732124874\n",
            "################################################################################\n",
            "Metric results\n",
            " rank_test_scores param_classifier:__choice__  mean_test_score  metric_balanced_accuracy  metric_precision  metric_recall  metric_f1  metric_custom_error\n",
            "                2               random_forest         0.621728                  0.621225          0.612022       0.603774   0.607870             0.378272\n",
            "                3                         lda         0.620419                  0.623348          0.588621       0.725067   0.649758             0.379581\n",
            "                9                 gaussian_nb         0.566754                  0.564169          0.564103       0.474394   0.515373             0.433246\n",
            "               11                 gaussian_nb         0.540576                  0.536536          0.536496       0.396226   0.455814             0.459424\n",
            "                4                 extra_trees         0.617801                  0.617937          0.603133       0.622642   0.612732             0.382199\n",
            "                1                    adaboost         0.636126                  0.639370          0.600000       0.752022   0.667464             0.363874\n",
            "                6                         mlp         0.613874                  0.614271          0.597436       0.628032   0.612352             0.386126\n",
            "                4                         mlp         0.617801                  0.618993          0.596107       0.660377   0.626598             0.382199\n",
            "                8                    adaboost         0.590314                  0.591144          0.572139       0.619946   0.595084             0.409686\n",
            "               12                  libsvm_svc         0.485602                  0.500000          0.485602       1.000000   0.653744             0.514398\n",
            "               10               decision_tree         0.560209                  0.562259          0.540230       0.633423   0.583127             0.439791\n",
            "                7               random_forest         0.599476                  0.598993          0.588556       0.582210   0.585366             0.400524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQr6C07Z_9nO"
      },
      "source": [
        "## **3-10- Tree-based Pipeline Optimization Tool (TPOT)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w0Babbr0aGe"
      },
      "source": [
        "!pip install tpot\n",
        "\n",
        "# check tpot version\n",
        "import tpot\n",
        "print('tpot: %s' % tpot.__version__)\n",
        "\n",
        "\n",
        "# example of tpot for a classification dataset\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from tpot import TPOTClassifier\n",
        "# define dataset\n",
        "\n",
        "#  X, y = make_classification(n_samples=100, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "# define model evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# define search\n",
        "model = TPOTClassifier(generations=5, population_size=50, cv=cv, scoring='accuracy', verbosity=2, random_state=1, n_jobs=-1)\n",
        "# perform the search\n",
        "# model.fit(X, y)\n",
        "model.fit(X_tr_scaled,y_train_b)\n",
        "# export the best model\n",
        "model.export('tpot_best_model.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLFSvqQaDq77"
      },
      "source": [
        "## **4- Charts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqG7Jof4UBbj"
      },
      "source": [
        "### **4-1- For Two Vehicle**\n",
        "\n",
        "> This part has been generated for better presentatiom of outputs. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g37qsllQH3uV"
      },
      "source": [
        "## Chart 1 - Hit a parked vehicle variation in different months\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "print(number_of_data)\n",
        "#months = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
        "months = ['January (1)','February (2)','March (3)','April (4)','May (5)','June (6)','July (7)','August (8)','September (9)','October (10)','November (11)','December (12)']\n",
        "months_count = two_vehic_df.groupby('C_MNTH').count().iloc[:, 1]\n",
        "months_percent = months_count / number_of_data * 100\n",
        "print(months_percent)\n",
        "x_data = months\n",
        "y1_data = months_percent\n",
        "y2_data = months_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'monthely'\n",
        "#------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()         # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show()\n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)\n",
        "#-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfOq9XZWEoTu"
      },
      "source": [
        "## Chart 2 - Hit a parked vehicle variation in different day of week\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "#week_day = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
        "week_day = ['Monday (1)','Tuesday (2)','Wednesday (3)','Thursday (4)','Friday (5)','Saturday (6)','Sunday (7)']\n",
        "week_day_count = two_vehic_df.groupby('C_WDAY').count().iloc[:, 1]\n",
        "week_day_percent = week_day_count / number_of_data * 100\n",
        "print(week_day_percent)\n",
        "x_data = week_day\n",
        "y1_data = week_day_percent\n",
        "y2_data = week_day_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'week_day'\n",
        "#------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)\n",
        "#-------------------------------------------------------------------------------------\n",
        "# print(week_day_count , week_day_count.sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEyLO2NyH0qF"
      },
      "source": [
        "## Chart 3 - Hit a parked vehicle variation in different times of a day\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "hour = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23']\n",
        "hour_count = two_vehic_df.groupby('C_HOUR').count().iloc[:, 1]\n",
        "hour_percent = hour_count / number_of_data * 100\n",
        "print(hour_percent)\n",
        "x_data = hour\n",
        "x_lable = 'Hour'\n",
        "y1_data = hour_percent\n",
        "y2_data = hour_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'times_of_a_day'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmv86YWGNubz"
      },
      "source": [
        "## Chart 4 - Age of Vehicle in hit a parked vehicle\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "veh_age_count = two_vehic_df.groupby('V_AGE').count().iloc[:, 1]\n",
        "print(veh_age_count.index)\n",
        "veh_age_percent = veh_age_count / number_of_data * 100\n",
        "print(veh_age_percent)\n",
        "x_data = veh_age_count.index\n",
        "#print(veh_age_count.V_AGE, veh_age_count)\n",
        "x_lable = 'Age of Vehicle'\n",
        "y1_data = veh_age_percent\n",
        "y2_data = veh_age_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'age_of_veh'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "plt.xlim(0,40)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4LwXTh3AlXo"
      },
      "source": [
        "## Chart 5 - Sex in hit a parked vehicle\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "driver_sex_count = two_vehic_df.groupby('P_SEX').count().iloc[:, 1]\n",
        "driver_sex_percent = driver_sex_count / number_of_data * 100\n",
        "# x_data = ['Male','Female'] #driver_sex_count.index\n",
        "x_data = ['Male (1)','Female (2)'] #driver_sex_count.index\n",
        "print(driver_sex_count)\n",
        "print(driver_sex_percent)\n",
        "x_lable = 'Person sex'\n",
        "y1_data = driver_sex_percent\n",
        "y2_data = driver_sex_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'Person_sex'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "#fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4mva9iQCVWU"
      },
      "source": [
        "## Chart 6 - Person age in hit a parked vehicle\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "print(number_of_data)\n",
        "person_age_count = two_vehic_df.groupby('P_AGE').count().iloc[:, 1]\n",
        "print(person_age_count.index)\n",
        "person_age_percent = person_age_count / number_of_data * 100\n",
        "print(person_age_percent.head(40))\n",
        "x_data = person_age_count.index\n",
        "#print(veh_age_count.V_AGE, veh_age_count)\n",
        "x_lable = 'Age of Person'\n",
        "y1_data = person_age_percent\n",
        "y2_data = person_age_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'age_of_person'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbL438t7yAVg"
      },
      "source": [
        "## Chart 7 - Driver age in hit a parked vehicle\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "#print(two_vehic_df[two_vehic_df['P_PSN'] == 11])\n",
        "number_of_data = two_vehic_df[two_vehic_df['P_PSN'] == 11]['C_MNTH'].count()\n",
        "print(number_of_data)\n",
        "driver_age_count = two_vehic_df[two_vehic_df['P_PSN'] == 11].groupby('P_AGE').count().iloc[:, 1]\n",
        "print(driver_age_count.index)\n",
        "driver_age_percent = driver_age_count / number_of_data * 100\n",
        "print(driver_age_percent.head(40))\n",
        "x_data = driver_age_count.index\n",
        "#print(veh_age_count.V_AGE, veh_age_count)\n",
        "x_lable = 'Age of Driver'\n",
        "y1_data = driver_age_percent\n",
        "y2_data = driver_age_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'age_of_driver'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xJ18Vzk2PCT"
      },
      "source": [
        "## Chart 8 - Traffic control type in hit a parked vehicle\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "traffic_cont_count = two_vehic_df.groupby('C_TRAF').count().iloc[:, 1]\n",
        "print(traffic_cont_count.index)\n",
        "traffic_cont_percent = traffic_cont_count / number_of_data * 100\n",
        "print(traffic_cont_percent)\n",
        "# x_data = traffic_cont_count.index\n",
        "# x_data =['Traffic signals fully operational',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Traffic signals in flashing mode',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Stop sign',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Yield sign',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Warning sign Yellow diamond shape sign',\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Pedestrian crosswalk',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Police officer',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'School guard, flagman',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'School crossing',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Reduced speed zone',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'No passing zone sign',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Markings on the road e.g. no passing',\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'School bus stopped with school bus signal lights flashing',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Railway crossing with signals, or signals and gates',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Railway crossing with signs only',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Control device not specified',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'No control present']\n",
        "# #\n",
        "# x_data =['Traffic signals fully operational (01)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Traffic signals in flashing mode (02)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Stop sign (03)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Yield sign (04)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Warning sign (05)',\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Pedestrian crosswalk (06)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Police office (07)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'School guard, flagman (08)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'School crossing (09)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Reduced speed zone (10)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'No passing zone sign (11)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Markings on the road (12)',\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'School bus stopped with flashing signal (13)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Railway crossing with signals, or signals and gates (15)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Railway crossing with signs only (16)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Control device not specified (17',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'No control present (18)']\n",
        "# #\n",
        "\n",
        "x_data =['Traffic signals fully operational (01)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Traffic signals in flashing mode (02)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Stop sign (03)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Yield sign (04)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Warning sign (05)',\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Pedestrian crosswalk (06)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Police office (07)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'School guard, flagman (08)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Reduced speed zone (10)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'No passing zone sign (11)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Markings on the road (12)',\t\t\t\t\t\t\t\t\t\t\t\n",
        "'School bus stopped with flashing signal (13)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Control device not specified (17',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'No control present (18)']\n",
        "x_lable = 'Traffic Control Type'\n",
        "y1_data = traffic_cont_percent\n",
        "y2_data = traffic_cont_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'traffic_cont'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-cj6jii_7Jp"
      },
      "source": [
        "## Chart 9 - Weather Conditions in hit a parked vehicle\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "weather_count = two_vehic_df.groupby('C_WTHR').count().iloc[:, 1]\n",
        "print(weather_count.index)\n",
        "weather_percent = weather_count / number_of_data * 100\n",
        "print(weather_percent)\n",
        "# x_data = weather_count.index\n",
        "# x_data =['Clear and sunny',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Overcast, cloudy but no precipitation',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Raining',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Snowing, not including drifting snow',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Freezing rain, sleet, hail',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Visibility limitation',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Strong wind']\n",
        "x_data =['Clear and sunny (1)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Overcast, cloudy but no precipitation (2)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Raining (3)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Snowing, not including drifting snow (4)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Freezing rain, sleet, hail (5)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Visibility limitation (6)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Strong wind (7)']\n",
        "x_lable = 'Weather Condition'\n",
        "y1_data = weather_percent\n",
        "y2_data = weather_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'weather_cond'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvx-qeKWLoRY"
      },
      "source": [
        "## Chart 10 - Road surface  Condition in hit a parked vehicle\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "road_surf_count = two_vehic_df.groupby('C_RSUR').count().iloc[:, 1]\n",
        "print(road_surf_count.index)\n",
        "road_surf_percent = road_surf_count / number_of_data * 100\n",
        "print(road_surf_percent.head(8))\n",
        "# x_data = road_surf_count.index\n",
        "# x_data =['Dry, normal','Wet','Snow (fresh, loose snow)','Slush, wet snow','Icy','Sand/gravel/dirt','Muddy','Oil']\n",
        "#x_data =['Dry, normal (1)','Wet (2)','Snow (fresh, loose snow) (3)','Slush, wet snow (4)','Icy (5)','Sand/gravel/dirt (6)','Muddy (7)','Oil (8)']\n",
        "x_data =['Dry, normal (1)','Wet (2)','Snow (fresh, loose snow) (3)','Slush, wet snow (4)','Icy (5)','Sand/gravel/dirt (6)','Muddy (7)']\n",
        "x_lable = 'Road Surface'\n",
        "y1_data = road_surf_percent\n",
        "y2_data = road_surf_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'road_sur_conf'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKftlESRLmjy"
      },
      "source": [
        "## Chart 11 - Road alignment in hit a parked vehicle\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "road_alig_count = two_vehic_df.groupby('C_RALN').count().iloc[:, 1]\n",
        "print(road_alig_count.index)\n",
        "road_alig_percent = road_alig_count / number_of_data * 100\n",
        "print(road_alig_percent.head(6))\n",
        "#x_data = road_alig_count.index\n",
        "x_data =['Straight and level (1)','Straight with gradient (2)','Curved and level (3)','Curved with gradient (4)','Top of hill or gradient (5)','Bottom of hill or gradient (6)']\n",
        "x_lable = 'Road Alignment'\n",
        "y1_data = road_alig_percent\n",
        "y2_data = road_alig_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'road_alignment_cond'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGLue2TRRULc"
      },
      "source": [
        "## Chart 12 - Road configuration in hit a parked vehicle\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "road_config_count = two_vehic_df.groupby('C_RCFG').count().iloc[:, 1]\n",
        "print(road_config_count.index)\n",
        "road_config_percent = road_config_count / number_of_data * 100\n",
        "print(road_config_percent.head(10))\n",
        "#x_data = road_config_count.index\n",
        "# x_data =['Non-intersection',\n",
        "# 'At an intersection of at least two public roadways',\n",
        "# 'Intersection with parking lot, private driveway, ...',\n",
        "# 'Railroad level crossing',\n",
        "# 'Bridge, overpass, viaduct',\n",
        "# 'Tunnel or underpass',\n",
        "# 'Passing or climbing lane',\n",
        "# 'Ramp',\n",
        "# 'Traffic circle',\n",
        "# 'Express lane of a freeway system']\n",
        "\n",
        "# x_data =['Non-intersection (01)',\n",
        "# 'At an intersection of at least two public roadways (02)',\n",
        "# 'Intersection with parking lot, private driveway, ... (03)',\n",
        "# 'Railroad level crossing (04)',\n",
        "# 'Bridge, overpass, viaduct (05)',\n",
        "# 'Tunnel or underpass (06)',\n",
        "# 'Passing or climbing lane (07)',\n",
        "# 'Ramp (08)',\n",
        "# 'Traffic circle (09)',\n",
        "# 'Express lane of a freeway system (10)']\n",
        "\n",
        "\n",
        "x_data =['Non-intersection (01)',\n",
        "'At an intersection of at least two public roadways (02)',\n",
        "'Intersection with parking lot, private driveway, ... (03)',\n",
        "'Railroad level crossing (04)',\n",
        "'Bridge, overpass, viaduct (05)',\n",
        "'Tunnel or underpass (06)',\n",
        "'Passing or climbing lane (07)',\n",
        "'Ramp (08)',\n",
        "'Traffic circle (09)']\n",
        "x_lable = 'Road Configuration'\n",
        "y1_data = road_config_percent\n",
        "y2_data = road_config_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'road_config_cond'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr1T4asQMK0G"
      },
      "source": [
        "## Chart 13 - Person Position in hit a parked vehicle\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "person_posi_count = two_vehic_df.groupby('P_PSN').count().iloc[:, 1]\n",
        "print(person_posi_count.index)\n",
        "person_posi_percent = person_posi_count / number_of_data * 100\n",
        "print(person_posi_percent.head)\n",
        "# x_data = person_posi_count.index\n",
        "# x_data =['Driver',\n",
        "# 'Front row, center',\n",
        "# 'Front row, right outboard,...',\n",
        "# 'Second row, left outboard,...',\n",
        "# 'Second row, center',\n",
        "# 'Second row, right outboard',\n",
        "# 'Third row, left outboard',\n",
        "# 'Third row, center',\n",
        "# 'Third row, right outboard',\n",
        "# 'Position unknown, but definitely an occupant',\n",
        "# 'Sitting on someone’s lap',\n",
        "# 'Outside passenger compartment',\n",
        "# 'Pedestrian']\n",
        "\n",
        "# x_data =['Driver (11)',\n",
        "# 'Front row, center (12)',\n",
        "# 'Front row, right outboard,... (13)',\n",
        "# 'Second row, left outboard,... (21)',\n",
        "# 'Second row, center (22)',\n",
        "# 'Second row, right outboard (23)',\n",
        "# 'Third row, left outboard (31)',\n",
        "# 'Third row, center (32)',\n",
        "# 'Third row, right outboard (33)',\n",
        "# 'Position unknown, but definitely an occupant (96)',\n",
        "# 'Sitting on someone’s lap (97)',\n",
        "# 'Outside passenger compartment (98)']\n",
        "\n",
        "x_data =['Driver (11)',\n",
        "'Front row, center (12)',\n",
        "'Front row, right outboard,... (13)',\n",
        "'Second row, left outboard,... (21)',\n",
        "'Second row, center (22)',\n",
        "'Second row, right outboard (23)',\n",
        "'Third row, left outboard (31)',\n",
        "'Third row, center (32)',\n",
        "'Third row, right outboard (33)',\n",
        "'Position unknown, but definitely an occupant (96)',\n",
        "'Sitting on someone’s lap (97)']\n",
        "# ,'Pedestrian (99)']\n",
        "x_lable = 'Person Position'\n",
        "y1_data = person_posi_percent\n",
        "y2_data = person_posi_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'person_pos_cond'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm6WvxoXWv2a"
      },
      "source": [
        "## Chart 14 - Person Position in hit a parked vehicle\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "person_safe_count = two_vehic_df.groupby('P_SAFE').count().iloc[:, 1]\n",
        "print(person_safe_count.index)\n",
        "person_safe_percent = person_safe_count / number_of_data * 100\n",
        "print(person_safe_percent.head)\n",
        "# x_data = person_safe_count.index\n",
        "# x_data =['No safety device used',\n",
        "# 'Safety device used',\n",
        "# 'Helmet worn',\n",
        "# 'Other safety device used',\n",
        "# 'No safety device equipped']\n",
        "x_data =['No safety device used (01)',\n",
        "'Safety device used (02)',\n",
        "'Helmet worn (09)',\n",
        "'Other safety device used (12)',\n",
        "'No safety device equipped (13)']\n",
        "x_lable = 'Person Safety'\n",
        "y1_data = person_safe_percent\n",
        "y2_data = person_safe_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'person_safe_cond'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN4fgqdn8zGi"
      },
      "source": [
        "## Chart 15 - Severity in hit a parked vehicle\n",
        "number_of_data = two_vehic_df['C_MNTH'].count()\n",
        "severity_count = two_vehic_df.groupby('P_ISEV').count().iloc[:, 1]\n",
        "print(severity_count.index)\n",
        "severity_percent = severity_count / number_of_data * 100\n",
        "print(severity_count.head(3))\n",
        "print(severity_percent.head(3))\n",
        "# x_data = severity_count.index\n",
        "# x_data =['No Injury',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Injury',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "# 'Fatality']\n",
        "x_data =['No Injury (1)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Injury (2)',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Fatality (3)']\n",
        "x_lable = 'Medical treatment required'\n",
        "y1_data = severity_percent\n",
        "y2_data = severity_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'severity_cond'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f2K3i4rLQ3N"
      },
      "source": [
        "import seaborn as sns  # for plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.set_palette(\"husl\",3)\n",
        "fig, ax1 = plt.subplots()\n",
        "fig.autofmt_xdate()\n",
        "plt.xlabel(x_lable)\n",
        "sns.barplot(x=x_data, y=y1_data)\n",
        "plt.grid(False)\n",
        "plt.ylabel(y1_lable)\n",
        "ax2 = plt.twinx()\n",
        "sns.barplot(x=x_data, y=y2_data, ax=ax2)\n",
        "plt.grid(False)\n",
        "plt.ylabel(y2_lable)\n",
        "# plt.show() \n",
        "plt.savefig((filename+'1.svg'), format='svg', dpi=300, transparent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2_FtJfXQi8l"
      },
      "source": [
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9Pxm4bRUVEF"
      },
      "source": [
        "### **4-2- For All Data**\n",
        "\n",
        "> This part has been generated for better presentatiom of outputs. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_BWvynLUyY_"
      },
      "source": [
        "## Chart 1 - different months\n",
        "number_of_data = cleaned_df['C_MNTH'].count()\n",
        "print(number_of_data)\n",
        "months = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
        "months_count = cleaned_df.groupby('C_MNTH').count().iloc[:, 1]\n",
        "months_percent = months_count / number_of_data * 100\n",
        "x_data = months\n",
        "y1_data = months_percent\n",
        "y2_data = months_count\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'monthely'\n",
        "#------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data,color='g')\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()         # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show()\n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)\n",
        "#-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru4rullVYOjI"
      },
      "source": [
        "## Chart 2 - different day of week\n",
        "number_of_data = cleaned_df['C_MNTH'].count()\n",
        "week_day = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
        "week_day_count = cleaned_df.groupby('C_WDAY').count().iloc[:, 1]\n",
        "week_day_percent = week_day_count / number_of_data * 100\n",
        "x_data = week_day\n",
        "y1_data = week_day_percent\n",
        "y2_data = week_day_count\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'week_day'\n",
        "#------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data,color='g')\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)\n",
        "#-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjUHhuLVZkez"
      },
      "source": [
        "## Chart 3 - different times of a day\n",
        "number_of_data = cleaned_df['C_MNTH'].count()\n",
        "hour = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23']\n",
        "hour_count = cleaned_df.groupby('C_HOUR').count().iloc[:, 1]\n",
        "print(hour_count.head(2))\n",
        "hour_percent = hour_count / number_of_data * 100\n",
        "x_data = hour\n",
        "x_lable = 'Hour'\n",
        "y1_data = hour_percent\n",
        "y2_data = hour_count\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'times_of_a_day'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data,color='g')\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ninHmzWZaZ0c"
      },
      "source": [
        "## Chart 4 - Age of Vehicle \n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = cleaned_df['C_MNTH'].count()\n",
        "veh_age_count = cleaned_df.groupby('V_AGE').count().iloc[:, 1]\n",
        "print(veh_age_count.index)\n",
        "veh_age_percent = veh_age_count / number_of_data * 100\n",
        "print(veh_age_percent.head(2))\n",
        "x_data = veh_age_count.index\n",
        "x_lable = 'Age of Vehicle'\n",
        "y1_data = veh_age_percent\n",
        "y2_data = veh_age_count\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'age_of_veh'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data,color='g')\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "plt.xlim(0,40)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0jf3aAzb1X_"
      },
      "source": [
        "## Chart 5 - Sex\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = cleaned_df['C_MNTH'].count()\n",
        "driver_sex_count = cleaned_df.groupby('P_SEX').count().iloc[:, 1]\n",
        "driver_sex_percent = driver_sex_count / number_of_data * 100\n",
        "\n",
        "x_data = ['Male','Female'] #driver_sex_count.index\n",
        "print(driver_sex_count)\n",
        "x_lable = 'Person sex'\n",
        "y1_data = driver_sex_percent\n",
        "y2_data = driver_sex_count\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'Person_sex'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data,color='g') #color='rgbkymc'\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "plt.show() \n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tm9VRWWc4Rj"
      },
      "source": [
        "## Chart 6 - Person age \n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = cleaned_df['C_MNTH'].count()\n",
        "print(number_of_data)\n",
        "person_age_count = cleaned_df.groupby('P_AGE').count().iloc[:, 1]\n",
        "print(person_age_count.index)\n",
        "person_age_percent = person_age_count / number_of_data * 100\n",
        "print(person_age_percent.head(2))\n",
        "x_data = person_age_count.index\n",
        "#print(veh_age_count.V_AGE, veh_age_count)\n",
        "x_lable = 'Age of Person'\n",
        "y1_data = person_age_percent\n",
        "y2_data = person_age_count\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'age_of_person'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data,color='g')\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uitMMMCQi_pO"
      },
      "source": [
        "## Chart 7 - Driver age\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = cleaned_df[cleaned_df['P_PSN'] == '11']['C_MNTH'].count()\n",
        "print(number_of_data)\n",
        "driver_age_count = cleaned_df[cleaned_df['P_PSN'] == '11'].groupby('P_AGE').count().iloc[:, 1]\n",
        "print(driver_age_count.index)\n",
        "driver_age_percent = driver_age_count / number_of_data * 100\n",
        "print(driver_age_percent)\n",
        "x_data = driver_age_count.index\n",
        "#print(veh_age_count.V_AGE, veh_age_count)\n",
        "x_lable = 'Age of Driver'\n",
        "y1_data = driver_age_percent\n",
        "y2_data = driver_age_count\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'age_of_driver'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naUqURH4j-US"
      },
      "source": [
        "## Chart 8 - Traffic control type \n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = cleaned_df['C_MNTH'].count()\n",
        "traffic_cont_count = cleaned_df.groupby('C_TRAF').count().iloc[:, 1]\n",
        "print(traffic_cont_count.index)\n",
        "traffic_cont_percent = traffic_cont_count / number_of_data * 100\n",
        "print(traffic_cont_percent.head(2))\n",
        "# x_data = traffic_cont_count.index\n",
        "x_data =['Traffic signals fully operational',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Traffic signals in flashing mode',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Stop sign',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Yield sign',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Warning sign Yellow diamond shape sign',\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Pedestrian crosswalk',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Police officer',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'School guard, flagman',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'School crossing',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Reduced speed zone',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'No passing zone sign',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Markings on the road e.g. no passing',\t\t\t\t\t\t\t\t\t\t\t\n",
        "'School bus stopped with school bus signal lights flashing',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Railway crossing with signals, or signals and gates',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Railway crossing with signs only',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Control device not specified',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'No control present']\n",
        "x_lable = 'Traffic Control Type'\n",
        "y1_data = traffic_cont_percent\n",
        "y2_data = traffic_cont_count\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'traffic_cont'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data,color='g')\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZi0J5IakmVY"
      },
      "source": [
        "## Chart 9 - Weather Condition\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = cleaned_df['C_MNTH'].count()\n",
        "weather_count = cleaned_df.groupby('C_WTHR').count().iloc[:, 1]\n",
        "print(weather_count.index)\n",
        "weather_percent = weather_count / number_of_data * 100\n",
        "print(weather_percent.head(2))\n",
        "# x_data = weather_count.index\n",
        "x_data =['Clear and sunny',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Overcast, cloudy but no precipitation',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Raining',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Snowing, not including drifting snow',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Freezing rain, sleet, hail',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Visibility limitation  e.g. drifting snow, fog, smog, dust, smoke, mist',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Strong wind',]\n",
        "x_lable = 'Weather Condition'\n",
        "y1_data = weather_percent\n",
        "y2_data = weather_count\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'weather_cond'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data,color='g')\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwnXFemM_nVR"
      },
      "source": [
        "## Chart 10 - Severity\n",
        "number_of_data = cleaned_df['C_MNTH'].count()\n",
        "severity_count_all = cleaned_df.groupby('P_ISEV').count().iloc[:, 1]\n",
        "print(severity_count_all.index)\n",
        "severity_percent_all = severity_count_all / number_of_data * 100\n",
        "print(severity_count_all.head(3))\n",
        "print(severity_percent_all.head(3))\n",
        "# x_data = severity_count_all.index\n",
        "x_data =['No Injury',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Injury',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Fatality']\n",
        "x_lable = 'Medical treatment required'\n",
        "y1_data = severity_percent_all\n",
        "y2_data = severity_count_all\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'severity_cond'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data,color='g')\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)\n",
        "print(number_of_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwuW6w3uEv9l"
      },
      "source": [
        "## Chart 10 - Severity compare\n",
        "barWidth = 0.25\n",
        "\n",
        "# x_data = severity_count.index\n",
        "x_data =['No Injury',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Injury',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Fatality']\n",
        "x_lable = 'Medical treatment required'\n",
        "y1_data = severity_percent_all\n",
        "y2_data = severity_percent\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'severity_cond_compare'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data,color='g', width = 0.1, label='National Collision')\n",
        "ax2.bar(x_data, y2_data,color='b', width = 0.1, label='Hit a parked motor vehicle')\n",
        "plt.grid(False)\n",
        "# ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "# ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "# ax2.bar(x_data, y2_data,color='b')\n",
        "# plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNjF0aJSlcVY"
      },
      "source": [
        "## Chart 10 - Collision Configuration \n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = cleaned_df['C_MNTH'].count()\n",
        "collision_conf_count = cleaned_df.groupby('C_CONF').count().iloc[:, 1]\n",
        "print(collision_conf_count.index)\n",
        "collision_conf_percent = collision_conf_count / number_of_data * 100\n",
        "print(collision_conf_percent)\n",
        "# x_data = collision_conf_count.index\n",
        "x_data =['Hit a moving object',\n",
        "'Hit a stationary object',\n",
        "'Ran off left shoulder',\n",
        "'Ran off right shoulder',\n",
        "'Rollover on roadway',\n",
        "'Any other single vehicle collision configuration',\n",
        "'Rear-end collision',\n",
        "'Side swipe',\n",
        "'One vehicle passing to the left of the other or left turn conflict',\n",
        "'One vehicle passing to the right of the other or right turn conflict',\n",
        "'Any other two vehicle - same direction of travel configuration',\n",
        "'Head-on collision',\n",
        "'Approaching side-swipe',\n",
        "'Left turn across opposing traffic',\n",
        "'Right turn, including turning conflicts',\n",
        "'Right angle collision',\n",
        "'Any other two-vehicle - different direction of travel configuration',\n",
        "'Hit a parked motor vehicle']\n",
        "x_lable = 'Collision Configuration'\n",
        "y1_data = collision_conf_percent\n",
        "y2_data = collision_conf_count\n",
        "y1_lable = 'National Collision (%)'\n",
        "y2_lable = 'Number of National Collision'\n",
        "filename = 'collision_configuration'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data,color='g')\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data,color='g')\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'_alldata.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n_Z7HslqD0N"
      },
      "source": [
        "# collision_conf_count = cleaned_df.groupby('C_CONF').count().iloc[:, 1]\n",
        "# print(collision_conf_count[collision_conf_count].sum())\n",
        "# print('Number of data before 2017:   ',sum(df['C_YEAR'] < 2017))\n",
        "print(collision_conf_percent[11])\n",
        "print(collision_conf_percent[0:6].sum().round(1))\n",
        "print(collision_conf_percent[6:11].sum().round(1))\n",
        "print(collision_conf_percent[11:17].sum().round(1))\n",
        "print(collision_conf_percent[17].round(1))\n",
        "collision_conf_percent[0:17].round(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37vTdVupUdX4"
      },
      "source": [
        "### **4-3- Other Presentoins**\n",
        "\n",
        "> This part has been generated for better presentatiom of outputs. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kohQuK2xf88W"
      },
      "source": [
        "ct= pd.crosstab(two_vehic_df.P_SEX,two_vehic_df.P_ISEV, margins=True)\n",
        "ct.to_excel('ct_sex_sev.xlsx')\n",
        "ct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utu5OA1FDuGd"
      },
      "source": [
        "grouped_p_severity = two_vehic_df.groupby('P_ISEV').count().reset_index().iloc[:,[0,1]]\n",
        "print(grouped_p_severity)\n",
        "grouped_p_severity.to_excel('G_Sev.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoqCkYBoj0mr"
      },
      "source": [
        "table = pd.pivot_table(two_vehic_df, values=['V_AGE', 'P_AGE'], index=['C_WDAY', 'P_SEX'],\n",
        "                       aggfunc={'V_AGE': [min, max, np.mean],'P_AGE': [min, max, np.mean]})\n",
        "table.to_excel('pivot_table.xlsx')\n",
        "table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzFUZZQpPSk7"
      },
      "source": [
        "two_vehic_df.groupby('C_WDAY').count().iloc[:, 5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmyfuSJY041b"
      },
      "source": [
        "## **5- Feature Importance for Controlable or Pridictable Data _(Can be Used to Inhance Radar Alarm Accuray_**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlO8HcX33qrC"
      },
      "source": [
        "### **5-1- Dropping Uncontrolable or unpredictable Columns**\n",
        " \n",
        "> In _`['C_RSUR',\t'V_TYPE',\t'P_SEX',\t'P_AGE',\t'P_PSN',\t'P_USER',\t'V_AGE']`_ columns there are no information that we can predict or control. Therefore, we drop them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC7t1SpLBKNX"
      },
      "source": [
        "un_cols=['C_RSUR','C_VEHS', 'V_TYPE',\t'P_SEX',\t'P_AGE',\t'P_PSN',\t'P_USER',\t'V_AGE']\n",
        "two_vehic_df_con = two_vehic_df.drop(un_cols, axis=1)\n",
        "two_vehic_df_con.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2u_-WsaB7VM"
      },
      "source": [
        "### **5-2- Create dummy variables based on all variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0h0CZZYCKco"
      },
      "source": [
        "cat_cols =[]\n",
        "two_vehic_df_con_cat = pd.get_dummies(two_vehic_df_con, columns=cat_cols, drop_first=True)\n",
        "two_vehic_df_con_cat.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRaepwt5C9Ss"
      },
      "source": [
        "### **5-3- Balancing the Dataset**\n",
        "https://elitedatascience.com/imbalanced-classes\n",
        "\n",
        "> Downsample majority class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TTUXro3C22K"
      },
      "source": [
        "two_vehic_df_con_cat_majority = two_vehic_df_con_cat[two_vehic_df_con_cat.P_ISEV==2]\n",
        "two_vehic_df_con_cat_minority = two_vehic_df_con_cat[two_vehic_df_con_cat.P_ISEV==1]\n",
        "print(two_vehic_df_con_cat_majority.shape[0])\n",
        "print(two_vehic_df_con_cat_minority.shape[0])\n",
        "\n",
        "from sklearn.utils import resample\n",
        "# Downsample majority class\n",
        "two_vehic_df_con_cat_majority_downsampled = resample(two_vehic_df_con_cat_majority, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=two_vehic_df_cat_minority.shape[0],     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        "two_vehic_df_con_cat_majority_downsampled.shape[0]\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "df_con_downsampled = pd.concat([two_vehic_df_con_cat_majority_downsampled, two_vehic_df_con_cat_minority])\n",
        "df_con_downsampled.P_ISEV.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzPW2aBZEooC"
      },
      "source": [
        "### **5-4- Partition into train and test**\n",
        "Use train_test_split from sklearn.model_selection to partition the dataset into 70% for training and 30% for testing.\n",
        "\n",
        "You can use the 70% for training set as both training and validation by using cross-validation.\n",
        "\n",
        "**Train and Test the model**  \n",
        "P_ISEV:<br>\n",
        "\n",
        "|Code| Description|\n",
        "|---------|-----------|\n",
        "|1|No Injury|\n",
        "|2|Injury|\n",
        "|3|Fatality\tDied immediately or within the time limit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RezlbKW6EvGY"
      },
      "source": [
        "target = 'P_ISEV' # Collision producing at least one injury\n",
        "features = list(df_con_downsampled.columns)\n",
        "features = [f for f in features if f!=target]\n",
        "# Separate input features (X) and target variable (y)\n",
        "X = df_con_downsampled[features]\n",
        "y = df_con_downsampled[[target]]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
        "\n",
        "print(features)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape) \n",
        "print(X_test.shape) \n",
        "print(y_test.shape)\n",
        "# Make target variable in numpy array format of 0 or 1\n",
        "y_train_b = 1*np.ravel(y_train)\n",
        "y_test_b = 1*np.ravel(y_test)\n",
        "y_train_b\n",
        "\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH10DPsxFJBj"
      },
      "source": [
        "### **5-5- Scaling Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUdtXqOhFd5N"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# For all datapoints\n",
        "min_max_scaler_all = MinMaxScaler()\n",
        "#---------------------------------|\n",
        "X_minmax = min_max_scaler_all.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_minmax, columns = X.columns)\n",
        "#---------------------------------\n",
        "print(min_max_scaler_all.scale_)\n",
        "#---------------------------------|\n",
        "print(X_scaled.shape)\n",
        "#---------------------------------\n",
        "# Just based on the training set\n",
        "min_max_scaler = MinMaxScaler()\n",
        "#---------------------------------|\n",
        "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
        "print(min_max_scaler.scale_)\n",
        "X_tr_scaled = pd.DataFrame(X_train_minmax, columns = X_train.columns)\n",
        "\n",
        "print(X_tr_scaled.shape)\n",
        "\n",
        "X_test_minmax = min_max_scaler.transform(X_test)\n",
        "X_te_scaled = pd.DataFrame(X_test_minmax, columns = X_test.columns)\n",
        "#---------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BOgOa78JwjL"
      },
      "source": [
        "### **5-6 Feature Importance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exQnAll2F3Xh"
      },
      "source": [
        "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=42)\n",
        "#---------------------------------|\n",
        "rnd_clf.fit( X,y)\n",
        "features = X.columns\n",
        "#---------------------------------\n",
        "feature_importance = {}\n",
        "#---------------------------------|\n",
        "for name, importance in zip(X.columns, rnd_clf.feature_importances_):\n",
        "#---------------------------------\n",
        "  feature_importance[name] = importance\n",
        "  \n",
        "feature_importance = [(k, feature_importance[k]) for k in sorted(feature_importance, key=feature_importance.get, reverse=True)]\n",
        "for k, v in feature_importance:\n",
        "  print(f\"{k}: {v:.3}\")\n",
        "\n",
        "importances = rnd_clf.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzyRASMIYTLF"
      },
      "source": [
        "print('-------------------------------------------------------------------------')\n",
        "two_vehic_fatality = two_vehic_df[two_vehic_df.P_ISEV == '3']\n",
        "print('The number of rows for \"two_vehic_fatality\" DataFrame is ', two_vehic_fatality['C_MNTH'].count())\n",
        "print('-------------------------------------------------------------------------')\n",
        "two_vehic_fatality.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVuPmxdrkokn"
      },
      "source": [
        "## Chart 1 - Hit a parked vehicle variation in different months\n",
        "number_of_data = two_vehic_fatality['C_MNTH'].count()\n",
        "print(number_of_data)\n",
        "months = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
        "months_count = two_vehic_fatality.groupby('C_MNTH').count().iloc[:, 1]\n",
        "months_percent = months_count / number_of_data * 100\n",
        "x_data = months\n",
        "y1_data = months_percent\n",
        "y2_data = months_count\n",
        "title = 'Fatality'\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'monthely_fatality'\n",
        "#------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_title(title)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()         # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show()\n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcnleHSCoLmY"
      },
      "source": [
        "## Chart 2 - Hit a parked vehicle variation in different day of week\n",
        "number_of_data = two_vehic_fatality['C_MNTH'].count()\n",
        "print(number_of_data)\n",
        "week_day = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
        "week_day_count = two_vehic_fatality.groupby('C_WDAY').count().iloc[:, 1]\n",
        "week_day_percent = week_day_count / number_of_data * 100\n",
        "x_data = week_day\n",
        "y1_data = week_day_percent\n",
        "y2_data = week_day_count\n",
        "title = 'Fatality'\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'weekday_fatality'\n",
        "#------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_title(title)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)\n",
        "#-------------------------------------------------------------------------------------\n",
        "# print(week_day_count , week_day_count.sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0S6X6F5ot6I"
      },
      "source": [
        "## Chart 3 - Hit a parked vehicle variation in different times of a day\n",
        "number_of_data = two_vehic_fatality['C_MNTH'].count()\n",
        "print(number_of_data)\n",
        "hour = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23']\n",
        "hour_count = two_vehic_fatality.groupby('C_HOUR').count().iloc[:, 1]\n",
        "print(hour_count.head(2))\n",
        "hour_percent = hour_count / number_of_data * 100\n",
        "x_data = hour\n",
        "title = 'Fatality'\n",
        "x_lable = 'Hour'\n",
        "y1_data = hour_percent\n",
        "y2_data = hour_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'times_of_a_day_fatality'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_title(title)\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2-5l5pEpqQp"
      },
      "source": [
        "## Chart 4 - Age of Vehicle in hit a parked vehicle\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = two_vehic_fatality['C_MNTH'].count()\n",
        "print(number_of_data)\n",
        "veh_age_count = two_vehic_fatality.groupby('V_AGE').count().iloc[:, 1]\n",
        "print(veh_age_count.index)\n",
        "veh_age_percent = veh_age_count / number_of_data * 100\n",
        "print(veh_age_percent.head(2))\n",
        "x_data = veh_age_count.index\n",
        "title = 'Fatality'\n",
        "x_lable = 'Age of Vehicle'\n",
        "y1_data = veh_age_percent\n",
        "y2_data = veh_age_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'age_of_veh_fatality'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_title(title)\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBrsTQnMqB8V"
      },
      "source": [
        "## Chart 5 - Sex in hit a parked vehicle\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = two_vehic_fatality['C_MNTH'].count()\n",
        "driver_sex_count = two_vehic_fatality.groupby('P_SEX').count().iloc[:, 1]\n",
        "driver_sex_percent = driver_sex_count / number_of_data * 100\n",
        "\n",
        "x_data = ['Male','Female'] #driver_sex_count.index\n",
        "print(driver_sex_count)\n",
        "title = 'Fatality'\n",
        "x_lable = 'Driver sex'\n",
        "y1_data = driver_sex_percent\n",
        "y2_data = driver_sex_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'driver_sex_fatality'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_title(title)\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "#fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EznqU6j8wXkM"
      },
      "source": [
        "## Chart 6 - Person age in hit a parked vehicle\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = two_vehic_fatality['C_MNTH'].count()\n",
        "person_age_count = two_vehic_fatality.groupby('P_AGE').count().iloc[:, 1]\n",
        "print(person_age_count.index)\n",
        "person_age_percent = person_age_count / number_of_data * 100\n",
        "print(person_age_percent.head(2))\n",
        "x_data = person_age_count.index\n",
        "title = 'Fatality'\n",
        "x_lable = 'Age of Person'\n",
        "y1_data = person_age_percent\n",
        "y2_data = person_age_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'age_of_person_fatality'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_title(title)\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMVUDaoY098h"
      },
      "source": [
        "## Chart 7 - Driver age in hit a parked vehicle\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = two_vehic_fatality[two_vehic_fatality['P_PSN'] == '11']['C_MNTH'].count()\n",
        "print(number_of_data)\n",
        "driver_age_count = two_vehic_fatality[two_vehic_fatality['P_PSN'] == '11'].groupby('P_AGE').count().iloc[:, 1]\n",
        "print(driver_age_count.index)\n",
        "driver_age_percent = driver_age_count / number_of_data * 100\n",
        "print(driver_age_percent.head(10))\n",
        "x_data = driver_age_count.index\n",
        "title = 'Fatality'\n",
        "x_lable = 'Age of Driver'\n",
        "y1_data = driver_age_percent\n",
        "y2_data = driver_age_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'age_of_driver_fatality'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_title(title)\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5_69RCF7cxd"
      },
      "source": [
        "## Chart 8 - Traffic control type in hit a parked vehicle\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = two_vehic_fatality['C_MNTH'].count()\n",
        "traffic_cont_count = two_vehic_fatality.groupby('C_TRAF').count().iloc[:, 1]\n",
        "print(traffic_cont_count.index)\n",
        "traffic_cont_percent = traffic_cont_count / number_of_data * 100\n",
        "print(traffic_cont_percent.head(2))\n",
        "# x_data = traffic_cont_count.index\n",
        "x_data =['Traffic signals fully operational',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Traffic signals in flashing mode',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Stop sign',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Yield sign',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Warning sign Yellow diamond shape sign',\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Pedestrian crosswalk',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Police officer',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'School guard, flagman',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'School crossing',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Reduced speed zone',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'No passing zone sign',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Markings on the road e.g. no passing',\t\t\t\t\t\t\t\t\t\t\t\n",
        "'School bus stopped with school bus signal lights flashing',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Railway crossing with signals, or signals and gates',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Railway crossing with signs only',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Control device not specified',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'No control present']\n",
        "title = 'Fatality'\n",
        "x_lable = 'Traffic Control Type'\n",
        "y1_data = traffic_cont_percent\n",
        "y2_data = traffic_cont_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'traffic_cont_fatality'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_title(title)\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)\n",
        "##-------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9-KbzuTB3dG"
      },
      "source": [
        "## Chart 9 - Weather Condition in hit a parked vehicle\n",
        "# C_YEAR\tC_MNTH\tC_WDAY\tC_HOUR\tC_SEV\tC_VEHS\tC_CONF\tC_RCFG\tC_WTHR\tC_RSUR\tC_RALN\tC_TRAF\tV_ID\tV_TYPE\tV_YEAR\tP_ID\tP_SEX\tP_AGE\tP_PSN\tP_ISEV\tP_SAFE\tP_USER\tC_CASE\n",
        "number_of_data = two_vehic_fatality['C_MNTH'].count()\n",
        "weather_count = two_vehic_fatality.groupby('C_WTHR').count().iloc[:, 1]\n",
        "print(weather_count.index)\n",
        "weather_percent = weather_count / number_of_data * 100\n",
        "print(weather_percent.head(2))\n",
        "# x_data = weather_count.index\n",
        "x_data =['Clear and sunny',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Overcast, cloudy but no precipitation',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Raining',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Snowing, not including drifting snow',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Freezing rain, sleet, hail',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Visibility limitation  e.g. drifting snow, fog, smog, dust, smoke, mist',\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "'Strong wind']\n",
        "title = 'Fatality'\n",
        "x_lable = 'Weather Condition'\n",
        "y1_data = weather_percent\n",
        "y2_data = weather_count\n",
        "y1_lable = 'Hit a parked motor vehicle (%)'\n",
        "y2_lable = 'Number of hits a parked vehicle'\n",
        "filename = 'weather_cond_fatality'\n",
        "##------------------------------------------------------------------------------------- \n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_title(title)\n",
        "ax1.set_xlabel(x_lable)\n",
        "ax1.set_ylabel(y1_lable)\n",
        "ax1.bar(x_data, y1_data)\n",
        "plt.grid(False)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.set_ylabel(y2_lable)  # we already handled the x-label with ax1\n",
        "ax2.bar(x_data, y2_data)\n",
        "plt.grid(False)\n",
        "fig.autofmt_xdate()\n",
        "plt.show() \n",
        "fig.savefig((filename+'.svg'), format='svg', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9h3xnWCYLd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "5143e0ea-82ae-4e95-9fba-634dcdb27210"
      },
      "source": [
        "two_vehic_df = pd.read_csv(\"https://raw.githubusercontent.com/mtofighi/RoadCollisions/master/two_vehic_df.csv\")\n",
        "two_vehic_df=two_vehic_df.drop('Unnamed: 0', axis=1)\n",
        "two_vehic_df.info()\n",
        "two_vehic_df.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30255 entries, 0 to 30254\n",
            "Data columns (total 17 columns):\n",
            "C_MNTH    30255 non-null int64\n",
            "C_WDAY    30255 non-null int64\n",
            "C_HOUR    30255 non-null int64\n",
            "C_VEHS    30255 non-null int64\n",
            "C_RCFG    30255 non-null int64\n",
            "C_WTHR    30255 non-null int64\n",
            "C_RSUR    30255 non-null int64\n",
            "C_RALN    30255 non-null int64\n",
            "C_TRAF    30255 non-null int64\n",
            "V_TYPE    30255 non-null int64\n",
            "P_SEX     30255 non-null int64\n",
            "P_AGE     30255 non-null int64\n",
            "P_PSN     30255 non-null int64\n",
            "P_ISEV    30255 non-null int64\n",
            "P_SAFE    30255 non-null int64\n",
            "P_USER    30255 non-null int64\n",
            "V_AGE     30255 non-null int64\n",
            "dtypes: int64(17)\n",
            "memory usage: 3.9 MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C_MNTH</th>\n",
              "      <th>C_WDAY</th>\n",
              "      <th>C_HOUR</th>\n",
              "      <th>C_VEHS</th>\n",
              "      <th>C_RCFG</th>\n",
              "      <th>C_WTHR</th>\n",
              "      <th>C_RSUR</th>\n",
              "      <th>C_RALN</th>\n",
              "      <th>C_TRAF</th>\n",
              "      <th>V_TYPE</th>\n",
              "      <th>P_SEX</th>\n",
              "      <th>P_AGE</th>\n",
              "      <th>P_PSN</th>\n",
              "      <th>P_ISEV</th>\n",
              "      <th>P_SAFE</th>\n",
              "      <th>P_USER</th>\n",
              "      <th>V_AGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_RCFG  ...  P_PSN  P_ISEV  P_SAFE  P_USER  V_AGE\n",
              "0       1       1       0       2       1  ...     11       2       2       1      6\n",
              "1       1       1      18       2       1  ...     11       2       2       1     12\n",
              "\n",
              "[2 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBpJtDygZps0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "1d0e0a02-85a6-4f9c-f099-8e30dc848421"
      },
      "source": [
        "cat_cols = ['C_MNTH','C_WDAY', 'C_HOUR','C_RCFG' , 'C_WTHR', 'C_RSUR' , 'C_RALN' , 'C_TRAF' , 'V_TYPE' , 'P_SEX' , 'P_PSN'  ,\t'P_SAFE' ,\t'P_USER' ]\n",
        "two_vehic_df_cat = pd.get_dummies(two_vehic_df, columns=[])\n",
        "two_vehic_df_cat.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C_MNTH</th>\n",
              "      <th>C_WDAY</th>\n",
              "      <th>C_HOUR</th>\n",
              "      <th>C_VEHS</th>\n",
              "      <th>C_RCFG</th>\n",
              "      <th>C_WTHR</th>\n",
              "      <th>C_RSUR</th>\n",
              "      <th>C_RALN</th>\n",
              "      <th>C_TRAF</th>\n",
              "      <th>V_TYPE</th>\n",
              "      <th>P_SEX</th>\n",
              "      <th>P_AGE</th>\n",
              "      <th>P_PSN</th>\n",
              "      <th>P_ISEV</th>\n",
              "      <th>P_SAFE</th>\n",
              "      <th>P_USER</th>\n",
              "      <th>V_AGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   C_MNTH  C_WDAY  C_HOUR  C_VEHS  C_RCFG  ...  P_PSN  P_ISEV  P_SAFE  P_USER  V_AGE\n",
              "0       1       1       0       2       1  ...     11       2       2       1      6\n",
              "1       1       1      18       2       1  ...     11       2       2       1     12\n",
              "\n",
              "[2 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}